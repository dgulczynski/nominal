% Opcje klasy 'iithesis' opisane sa w komentarzach w pliku klasy. Za ich pomoca
% ustawia sie przede wszystkim jezyk oraz rodzaj (lic/inz/mgr) pracy.
\documentclass[english, mgr]{iithesis}

\usepackage[utf8]{inputenc}

%%%%% DANE DO STRONY TYTUŁOWEJ
% Niezaleznie od jezyka pracy wybranego w opcjach klasy, tytul i streszczenie
% pracy nalezy podac zarowno w jezyku polskim, jak i angielskim.
% Pamietaj o madrym (zgodnym z logicznym rozbiorem zdania oraz estetyka) recznym
% zlamaniu wierszy w temacie pracy, zwlaszcza tego w jezyku pracy. Uzyj do tego
% polecenia \fmlinebreak.
\englishtitle   {Domain-specific logic \fmlinebreak for terms with variable binding}
\polishtitle    {Logika dziedzinowa do wnioskowania \fmlinebreak o termach z wiązaniem zmiennych}
\polishabstract {Przedstawiamy logikę dziedzinową do wnioskowania o termach z wiązaniem zmiennych. }
\englishabstract{We describe logic for reasoning about terms with variable bindings.}
\author         {Dominik Gulczyński}
\advisor        {dr Piotr Polesiuk}
\date           {\today}                     % Data zlozenia pracy
% Dane do oswiadczenia o autorskim wykonaniu
\transcriptnum  {299391}                     % Numer indeksu
\advisorgen     {dr. Piotra Polesiuka} % Nazwisko promotora w dopelniaczu
%%%%%

%%%%% WLASNE DODATKOWE PAKIETY
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd} % For \llbracket
\usepackage{macros}
\usepackage{mathpartir}
\usepackage{mathtools}
\usepackage{listings}
\usepackage{semantic}
\usepackage{sourcecodepro}
\usepackage{enumitem}
\usepackage{tabularx}
\usepackage{makecell}
\usepackage{mdframed}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage[toc,page]{appendix}
\usepackage{multicol}
\usepackage{multirow}

%%%%% WŁASNE DEFINICJE I POLECENIA
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{ocamlstyle}{
    commentstyle=\color{codegreen},
    escapebegin=\color{black},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=ocamlstyle}
\lstdefinelanguage{OCaml}[]{caml}{
    morekeywords={val, ProofEnv, otherwise},
    otherkeywords = {|>, \%>, +=, -=, ->, ::}
}
\setlist{nolistsep}
\renewcommand{\tt}[1]{\texttt{\small{#1}}}
\renewcommand{\it}[1]{\textit{#1}}
\newcommand{\aequiv}{\ensuremath{=_\alpha}}
\newcommand{\solverRule}{\vdash}
\newcommand{\NeqAtoms}{\tt{neq\_atoms}}
\newcommand{\Fresh}{\tt{fresh}}
\newcommand{\VarShape}{\tt{var\_shape}}
\newcommand{\Shape}{\tt{shape}}
\newcommand{\Subshape}{\tt{subshape}}
\newcommand{\Symbols}{\tt{symbols}}
\newcommand{\TransferShape}{\tt{transfer\_shape}}
\newcommand{\Assumptions}{\tt{assumptions}}
\newcommand{\occurs}[2]{\ensuremath{ {#1}\text{ occurs in }{#2}}}
\newcommand{\stxoccurs}[2]{\ensuremath{ {#1}\text{ occurs syntactically in }{#2}}}
\newcommand{\pluseq}{\mathrel{+}=}
\newcommand{\minuseq}{\mathrel{-}=}
\newcommand{\shrep}[2][\icEnv]{\ensuremath{ #2_{#1}}}
\newcommand{\shenv}[2][\icEnv]{\ensuremath{ |#2|_{#1}}}
\newcommand{\fix}[3]{\ensuremath{\text{fix }#1(#2)\ofkind#3=}}
\newcolumntype{L}{X}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\newcolumntype{R}{>{\raggedleft\arraybackslash}X}
\usepackage[backend=bibtex]{biblatex}
\addbibresource{references.bib}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
% \section{Motivation}
One of the fundamental distinctions between conducting proofs manually with pen and paper
and using a computer lies in the flexibility and liberties one can take in the first case.
Human provers and reviewers often agree upon unexplained or unproven assumptions
and may skip some unimportant boilerplate.
Computers, on the other hand, are less forgiving
and demand transparency and justification down to the smallest details.

A common assumption we commonly make when writing pen-and-paper proofs pertains to
working with abstract syntax trees,
where we assume that the variables we choose are fresh enough
or that substitutions avoid issues like variable capture.
For instance, when dealing with lambda calculus, we often construct inductive proofs
over the structure of expression, where in the case for an abstracion we will implicitly only show
the case where the variable bound in that abstraction is \it{sufficiently fresh}.
Addressing the general case could introduce unnecessary complexities unrelated to the theorem at hand.
Justifiably, we skip over this detail --- however, the induction principle obliges us to prove the case for arbitrary variable names.

% \section{Problem statement}
Addressing this gap in formal reasoning requires careful considerations to come up with a resolution.
Fortunately, there exist some solutions to that problem --- and one particular
approach, coined \it{nominal logic} and introduced by Andrew M. Pitts\cite{pitts2003} is of most interest to this work.

\section{Nominal approach}
Pitts' work introduces \it{nominal logic}, a first-order theory of names, swapping, and freshness,
that amongst other novelties, introduces the precise mathematical definition
describing the concept of "sufficiently fresh names",
which, as Pitts argues, bridges the gap between formal mathematical reasoning and the informal practices mentioned earlier.

\begin{mdframed}[frametitle={Pitts, 2003\cite{pitts2003}}]
Names of what? Names of entities that may be subject to binding by some of
the syntactical constructions under consideration. In Nominal Logic these sorts of
names, the ones that may be bound and hence that may be subjected to swapping
without changing the validity of predicates involving them, will be called atoms.
\end{mdframed}
TODO: frame below is rather awkward
\begin{mdframed}[frametitle={Pitts, 2003\cite{pitts2003}}]
Why the emphasis on the operation of swapping two names, rather than on the
apparently more primitive notion of renaming one name by another? The answer
to this question lies in the combination of the following two facts.

\begin{enumerate}
  \item First, even though swapping seems less general than renaming (since after all,
  the act of swapping \(a\) and \(b\) can be expressed as the simultaneous renaming
  of \(b\) by \(a\) and \(a\) by \(b\)), it is possible to found a theory of syntax modulo
  \(\alpha\)-equivalence, free and bound variables, substitution, etc., upon this notion—
  this is the import of the work in \cite{subnbinders}.
  \item Secondly, swapping is an involutive operation: a swap followed by the same
  swap is equivalent to doing nothing. This means that the class of equivariant
  predicates, i.e., those whose validity is invariant under atom-swapping, has
  excellent logical properties. It contains the equality predicate and is closed
  under negation, conjunction, disjunction, existential and universal quantification,
  formation of least and greatest fixed points of monotone operators, etc., etc.
  The same is not true for renaming. For example, the validity of a
  negated equality between atoms is not necessarily preserved under renaming.
\end{enumerate}

In other words, we can found a theory of variable-binding upon swapping, and it
is convenient to do so because of its good logical properties.
\end{mdframed}

A crucial takeaway from Pitts' work is that switching from substitutions to permutations of names
allows for all necessary concepts, including alpha-equivalence, freshness, and variable-binding,
to be defined solely in terms of the operation of swapping pairs of names.
As an example, consider the abstract syntax tree of untyped lambda calculus,
given by the grammar below, where $a$ ranges over an infinite set of names --- or rather \it{atoms}.
\begin{figure}[htbp]
  \centering
  \begin{tabularx}{\textwidth}{|CXr|}
      \hline & & \\
  $ t \deff a \mid \lambda a . t \mid t\;t $
  & & (lambda terms)
  \\ & & \\ \hline
\end{tabularx}
  \caption{Terms of untyped lambda calculus}
  \label{fig:lambda-calculus}
\end{figure}
\begin{figure}[htbp]
  \centering
  \begin{tabularx}{\textwidth}{|XX|}
      \hline & \\
      \begin{tabular}{rcl}
      $\permswap{a}{b}{(\lambda c . t)} $ & $:=$
      & $ \lambda (\permswap{a}{b}{c}) . (\permswap{a}{b}{t})$ \\
      $\permswap{a}{b}{(t_1\; t_2)} $ & $:=$
      & $ (\permswap{a}{b}{t_1}) \; (\permswap{a}{b}{t_2}) $
      \end{tabular}
      &
      $\permswap{a}{b}{c} := \begin{cases}
          a & \text{if } c = b \\
          b & \text{if } c = a \\
          c & \text{otherwise}
        \end{cases}$
      \\ &  \\
      \hline
\end{tabularx}
  \caption{Swapping procedure}
  \label{fig:swap}
\end{figure}
\\
The definition of swapping atoms $a$ and $b$ in some tree $t$,
written $\permswap{a}{b}{\:t}$, is rather straightforward.
It naturally follows the tree structure, touching only the affected atoms,
and doesn't need to distinct betwen free and bound names (like substitutions do),
but simply changes them all the same exact way.

\begin{figure}[htbp]
  \centering
    \begin{tabularx}{\textwidth}{|CCCC|}
      \hline & & & \\
      $
      \inference{
        a \cneq b
      }{
        a \cfresh b
      }
      $ & $
      \inference{
        a \cfresh t_1 & a \cfresh t_2
      }{
        a \cfresh t_1\;t_2
      }
      $ & $
      \inference{
      }{
        a \cfresh \lambda a . t
      }
      $ & $
      \inference{
        a \cfresh t
      }{
        a \cfresh \lambda b . t
      }
      $ \\ & & & \\ \hline
    \end{tabularx}
  \caption{Freshness relation}
  \label{fig:fresh}
\end{figure}
Relation of \it{freshness} of atom $a$ in tree $t$, written $a \cfresh t$,
is similarly simple to define.\footnote{Pitts defines it as
$a$ not being a member of the \it{support set} of $t$ ---
but for our purposes, the simple inductive definition will suffice.}\
Note that it only assumes the comparability of atoms
and is an \it{equivariant} relation, meaning that
it's validity is invariant under swapping atoms
--- which can be shown by simplest induction.

\begin{figure}[htbp]
  \centering
    \begin{tabularx}{\textwidth}{|ccCcc|}
    \hline & & & & \\ {} &
    $
    \inference{
      \text{}
    }{
      a \aequiv a
    }
    $ & $
    \inference{
      t_1 \aequiv t_1' & t_2 \aequiv t_2'
    }{
      t_1\;t_2 \aequiv t_1'\;t_2'
    }
    $ & $
    \inference{
      \permswap{a}{b}{t} \aequiv \permswap{a'}{b}{t'} & b \cfresh t & b \cfresh t'
    }{
      \lambda a . t \aequiv \lambda a' . t'
    }
    $ & {} \\ & & & & \\ \hline
    \end{tabularx}
  \caption{Alpha-equivalence relation}
  \label{fig:fresh}
\end{figure}
With \it{swapping} and \it{freshness} already established,
we define the alpha-equivalence of terms, written $t_1 \aequiv t_2$.
As we built this definition of alpha-equivalence using only induction,
swapping, and freshness then, as Pitts argues, it is equivariant as well.
\begin{mdframed}[frametitle={Pitts, 2003}]
The fundamental assumption underlying Nominal Logic is that \textit{the only predicates we ever deal with} (when describing properties of syntax) \textit{are equivariant ones, in the sense that their validity is invariant under swapping} (i.e., transposing, or interchanging) \textit{names}.
\end{mdframed}

\section{Contributions}
We categorize the fundamental properties of terms with variable binding,
such as alpha equivalence and freshness, as \textit{constraints}.
We introduce \textit{the Solver}, an algorithm designed to automatically
resolve new constraints based on the pre-established ones.
It serves as the logical core of the constraints sublogic,
that together with the embedding of constraints into propositional formulas
constructs a higher-order logic capable of seamlessly expressing these properties.
This approach we've taken, liberates users from the painstaking task of manually proving the seemingly trivial but crucial details, through automated resolution of constraints,
while ensuring the completeness and correctness of written proofs.

For the user interface, we have developed a proof checker and proof assistant,
tying all the parts together in a cohesive framework.
The proof assistant draws inspiration from the HOL family of theorem provers,
initially introduced by Michael J. C. Gordon\cite{HOL}.
Similar to HOL, it utilizes the OCaml programming language as the
interface to writing proofs and encoding theorems.
While currently somewhat low-level, with further automation efforts,
it should achieve intuitiveness and user-friendliness akin to other,
more mature and powerful proof assistants.

\section{Related work}
Of course, there's other works that focus on reasoning about
syntactical properties of binders, as they are essential
in formalizing properites of programming languages.

\begin{itemize}
\item \textbf{Higher-Order Abstract Syntax} (HOAS) introduced by Frank Pfenning
and Conal Elliott\cite{hoas}
is a uniform and generic representation of terms, formulas, programs, and other
syntactic objects used in formal reasoning systems that focus on substitution and
unification under the presence of binders.
Authors utilize the binding construct of the implementation language to represent the binding in the language being formalized.
\\

\item \textbf{Parametric Higher-Order Abstract Syntax} (PHOAS) improves
on the idea of HOAS, by utilizing dependently-typed abstract syntax trees to
formalize HOAS in general-purpose type theories, like Coq's Calculus of Inductive Constructions.
Introduced by Adam Chlipala\cite{phoas}, it has been used to develop certified, executable program transformations over several formalizations of statically-typed functional programming languages.
\\

\item \textbf{Locally Nameless Representation} is
an approach to representation of syntax with variable binders,
introduced by Arthur Charguéraud\cite{locally-nameless}.
It represents the bound variables through de Bruijn indices, while retaining
names of the free variables, achieving strong induction principles.
Utilizing the Coq library TLC developed by Charguéraud, the approach has successfully formalized diverse type systems and semantics.
\\

\item \textbf{Autosubst}\cite{autosubst}
is a Coq library that automates some crucial parts of formalizing syntactic theories with variable binders,
developed by Steven Schäfer, Tobias Tebbi, and Gert Smolka.
Authors employ de Bruijn representation of terms with additional binding annotations
to automatically derive the substitution operation and proofs of substitution lemmas.
They introduce an automation tactic that solves equations involving terms and substitutions,
based on their work on the decision procedure of equational theory of
an extension of the sigma-calculus by Abadi et al\cite{sigma-calculus}.

\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Terms and constraints}
To properly describe our framework and constraints sublogic,
we must start with the simplest elements: \it{names}, \it{terms}, and \it{constraints}.

The names are drawn from an infinite set of \it{atoms} (represented by lowercase letters)
and correspond to the bound variables in terms, analogous to the variables in the lambda calculus.
This set is disjoint from the set of variables commonly used in first-order logic,
which we will refer to as \it{variables} (denoted by uppercase letters).

The terms are constructed to mimic the structure of abstract syntax trees of the lambda calculus,
extending it with notion of permutations (of atoms) and functional symbols,
denoted by metavariable $\symb$,
that are drawn from yet another set disjoint with atoms and variables.

The constraints are precise descriptions of syntactical properties,
describing the relationship between their arguments --- atoms and terms.
\begin{figure}[htbp]
  \centering
  \framebox[\textwidth]{
    \begin{tabularx}{\textwidth}{rcl@{\extracolsep{\fill}}r}
      $\perm$    & $\deff$ & $\permid
                          \mid \permswap{\atomexp}{\atomexp}{\perm}$
      & (permutations) \\
      $\atomexp$ & $\deff$ & $\perm \apperm \atomv$
      & (atom expressions) \\
      $\term$    & $\deff$ & $\atomexp
                         \mid \perm \apperm \termv
                         \mid \tbind{\atomexp} \term
                         \mid \term \tapp \term
                         \mid \symb$
      & (terms) \\
      $\constr$  & $\deff$ & $\atomexp \cfresh \term
                         \mid \term \ceq \term
                         \mid \term \csheq \term
                         \mid \term \cshlt \term
                         \mid \csymb \term$
      & (constraints)
    \end{tabularx}
  }
  \caption{Syntax of constraint sublogic}
  \label{fig:terms-constraints-syntax}
\end{figure}

Construction $\tbind{\atomexp} \term$ represents a \it{binder} ---
informally, we think of it as binding the occurences of $\atomexp$ in $\term$,
similarly to a lambda abstraction --- yet it \it{isn't} a binder,
but a simple syntactical construction glueing together an atom with another term.
The semantics of binding will apply only after we interpret this syntactical term in the model.

Also note that we do not restrict this construction to the form of $\tbind{\atomv} \term$,
but allow permuted atoms to appear under binders.
Additionaly, when dealing with atom expressions with identity permutation $\permid \;\atomv$
we will skip the permutation and simply write $\atomv$,
and sometimes call such atom expressions \it{pure}.
The same rules apply to permuted variables.

\begin{figure}[htbp]
  \centering
  \begin{tabularx}{\linewidth}{|l|X|}
    \hline
    $\atomexp \cfresh \term$ & Atom $\atomexp$ is fresh in term $\term$, meaning it does not occur in $\term$ as a free variable. \\
    \hline
    $\term_1 \ceq \term_2$ & Terms $\term_1$ and $\term_2$ are alpha-equivalent. \\
    \hline
    $\term_1 \csheq \term_2$ & Terms $\term_1$ and $\term_2$ possess an identical shape, i.e., after erasing all atoms, terms $\term_1$ and $\term_2$ would be equal. \\
    \hline
    $\term_1 \cshlt \term_2$ & The shape of term $\term_1$ is structurally smaller than the shape of term $\term_2$, i.e., after erasing all atoms, $\term_1$ would be equal to some subterm of $\term_2$. \\
    \hline
    $\csymb \term$ & term $\term$ is equal to some functional symbol. \\
    \hline
  \end{tabularx}
  \caption{Informal semantics of constraints}
  \label{fig:informal-constraints-semantics}
\end{figure}

It's important to note that these terms and constraints are merely a data structure
and do not incorporate notions of computation, reduction, or binding by themselves.
These properties only appear in the sublogic of constraints after we interpret
constraints within the logical model, which allows us to then reason about
concepts such as \it{freshness}, \it{variable binding}, and \it{structural} order.

\section{Model}
To build the mathematical model of terms and constraints,
we introduce \it{semantic terms} and \it{semantic shapes} that will inhabit it.
We will use metavariable $\sematom$ for \it{semantic names} drawn from an
infinite set of names, representing the free variables.
\begin{figure}[htbp]
  \centering
  \framebox[\textwidth]{
    \begin{tabularx}{\textwidth}{rcl@{\extracolsep{\fill}}r}
      $\semterm$ & $\deff$ & $\sematom
                        \bnfor n
                        \bnfor \stbind \semterm
                        \bnfor \semterm \stapp \semterm
                        \bnfor \symb$
      & (semantic terms) \\
      $\semshape$ & $\deff$ & $\shatom
                        \bnfor \stbind \semshape
                        \bnfor \semshape \stapp \semshape
                        \bnfor \symb$
      & (semantic shapes)
    \end{tabularx}
  }
  \caption{Semantic representation of terms and shapes}
  \label{fig:semantic-terms-shapes}
\end{figure}
\\
Binders in semantic terms are achieved by De Bruijn indices\cite{deBruijn} and consequently
the bound names are represented by natural numbers, denoted by $n$,
and the binding construction has no explicit argument, denoted by $\stbind$.
\begin{figure}[htbp]
  \centering
  \framebox[\textwidth]{
    \begin{subfigure}{0.45\textwidth}
      \begin{eqnarray*}
        \termMdl{\perm \apperm \atomv}{\tmEnv} & = &
          \permMdl{\perm}{\tmEnv}(\tmEnv(\atomv)) \\
        \termMdl{\perm \apperm \termv}{\tmEnv} & = &
          \permMdl{\perm}{\tmEnv}(\tmEnv(\termv)) \\
        \termMdl{\tbind{\atomexp} \term}{\tmEnv} & = &
          \stbind (\termMdl{\term}{\tmEnv} \shiftIdx)
            \subst{\termMdl{\atomexp}{\tmEnv}}{0} \\
        \termMdl{\term_1 \tapp \term_2}{\tmEnv} & = &
          \termMdl{\term_1}{\tmEnv} \stapp \termMdl{\term_2}{\tmEnv} \\
        \termMdl{\symb}{\tmEnv} & = & \symb \\
      \end{eqnarray*}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
      \begin{eqnarray*}
        \shapeof{\sematom}                     & = & \shatom \\
        \shapeof{n}                            & = & \shatom \\
        \shapeof{\stbind \semterm}             & = & \stbind \shapeof{\semterm} \\
        \shapeof{\semterm_1 \stapp \semterm_2} & = &
          \shapeof{\semterm_1} \shapp \shapeof{\semterm_2} \\
      \end{eqnarray*}
    \end{subfigure}
  }
  \caption{Interpretation of terms and shapes in the model}
  \label{fig:terms-shapes-interpretation}
\end{figure}
\\
The term interpretation function, denoted $\termMdl{\cdot}{\tmEnv}$,
maps syntactic terms to semantic terms,
utilizing the standard shifting of De Bruijn indices (denoted by { }$\shiftIdx$).
It is parametrized by function $\tmEnv$ that maps atoms and variables to
semantic shapes.\\
The shape interpretation function, denoted $\shapeof{\cdot}$,
maps semantic terms to semantic shapes by erasing names.

With above machinery, we can establish relation $\tmEnv \vDash \constr$
that interprets the constraints in our model, using some mapping $\tmEnv$.
\begin{figure}[htbp]
  \centering
  \framebox[\textwidth]{
    \begin{tabular}{lclr} \\
      $\tmEnv \vDash \term_1 \ceq \term_2 $  & \textrm{iff} &
        $\termMdl{\term_1}{\tmEnv} = \termMdl{\term_2}{\tmEnv}$ \\
      $\tmEnv \vDash \atomexp \cfresh \term$ & \textrm{iff} &
        $\termMdl{\atomexp}{\tmEnv} \notin
          \mathsf{FreeAtoms}(\termMdl{\term}{\tmEnv})$ \\
      $\tmEnv \vDash \term_1 \csheq \term_2$ & \textrm{iff} &
        $\shapeof{\termMdl{\term_1}{\tmEnv}} = \shapeof{\termMdl{\term_2}{\tmEnv}}$ \\
      $\tmEnv \vDash \term_1 \cshlt \term_2$ & \textrm{iff} &
        $\shapeof{\termMdl{\term_1}{\tmEnv}} \textrm{ is a strict subshape of }
          \shapeof{\termMdl{\term_2}{\tmEnv}}$ \\ \\
    \end{tabular}
  }
  \caption{Constraint interpretation in the model}
  \label{fig:constraint-interpretation}
\end{figure}
\\
Note that the freshness can be expressed through membership check of $\mathsf{FreeAtoms}$ set,
which is trivial to compute as a consequence of using of De Bruijn indices.
Note that  it's possible for terms of form $\tbind{a}{X}$ and $\tbind{b}{Y}$
to be equal in this model.

We will use metavariable $\cEnv$ to represent finite sets of constraints,
and write $\tmEnv \vDash \cEnv$ if for all $\constr \in \cEnv$,
we have $\tmEnv \vDash \constr$,
as well as write $\cEnv \vDash \constr$ if for every $\tmEnv$ such that $\tmEnv \vDash \cEnv$,
we have $\tmEnv \vDash \constr$.
In the next chapter, we present the deterministic \it{Solver} algorithm
that emulates this model by syntatically verifying statements of form $\cEnv \vDash \constr$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Constraint solver} \label{sec:solver}
At the heart of our work lies the Solver, an algorithm designed to resolve constraints.
For any assumed constraints $\constr_1, \dots, \constr_n$, and
goal constraint $\constr_0$, the Solver determines whether judgment $\constr_1, \dots, \constr_n \vDash \constr_0$ holds.
Meaning that for every possible substitution of variables into closed terms in constraints $\constr_0, \constr_1, \dots, \constr_n$,
such that $\constr_1, \dots, \constr_n$ are satisfied, would also satisfy $\constr_0$.

For the sake of convenience and implementation efficiency, the Solver operates
on its own internal representation of constraints, that slightly differs from
constraints described in the previous section.
It erases atoms in terms under shape constraints,
effectively transforming them into \it{shapes}.
We will write $\atomv \cneq \atomexp$ instead of $\atomv \cfresh \atomexp$ as it gives a clear intuition of atom freshness implying inequality.
\begin{figure}[htbp]
  \centering
  \framebox[\textwidth]{
    \begin{tabularx}{\textwidth}{rcl@{\extracolsep{\fill}}r}
      $\sconstr$ & $\deff$ & $\atomexp \cfresh \term
                       \bnfor \term \ceq \term
                       \bnfor \shape \csheq \shape
                       \bnfor \shape \cshlt \shape
                       \bnfor \csymb \term$
      & (solver constraints) \\
      $\shape$ & $\deff$ & $\shatom
                     \bnfor \termv
                     \bnfor \shbind \shape
                     \bnfor \shape \tapp \shape
                     \bnfor \symb$
      & (shapes) \\
    \end{tabularx}
  }
  \caption{Solver internal representation of terms and shapes}
  \label{fig:solver-internal-representation-terms-shapes}
\end{figure}

A high level perspective of the Solver is that it works on judgments of form
$\cEnv; \icEnv \solverRule \sconstr$, veryfying  whether a given goal-constrint $\sconstr$
holds in environments of assumed constraints (kept in $\cEnv$ and $\icEnv$)
through dissecting constraints on both sides of the turnstile into
irreducible components that are straightforward to handle.
\begin{figure}
  \centering
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    $\atomv_1 \cneq \atomv_2$
    & Atoms $\atomv_1$ and $\atomv_2$ are different.
    \\ \hline
    $\atomv   \cfresh \termv$
    & Atom $\atomv$ is {Fresh} in variable $\termv$.
    \\ \hline
    $\termv_1 \csheq  \termv_2$
    & Variables $\termv_1$ and $\termv_2$ posses the same shape.
    \\ \hline
    $\termv   \csheq  \term$
    & Variable $\termv$ has a shape of term $\term$.
    \\ \hline
    $\term    \cshlt  \termv$
    & Term $\term$ strictly subshapes variable $\termv$.
    \\ \hline
    $\csymb \termv$
    & Variable $\termv$ is some functional symbol.
    \\ \hline
  \end{tabularx}
  \caption{Irreducible constraints}
  \label{fig:irreducible-constraints}
\end{figure}
Environment $\cEnv$ keeps the yet unprocessed assumptions,
while another environment $\icEnv$ keeps track of already analysed and irreducible assumptions.
These assumptions usually flow from the former to the latter, but if we analyse
a constraint that that affects other assumptions in $\icEnv$,
they may flow back to $\cEnv$ to be further disected by the Solver.


After all assumptions in $\cEnv$ are reduced to irreducible constraints,
we break down the goal-constraint $\sconstr$ and repeat the reduction procedure on
new assumptions and goal.
\begin{figure}[htpb]
  \centering
    \begin{tabularx}{\textwidth}{|CCC|}
    \hline & & \\ $
      \inference{
      }{
        \cEnv ; \lightning \solverRule \sconstr
      }
      $ & $
      \inference{
        \sconstr \text{ is trivial}
      }{
        \cEnv ; \icEnv \solverRule \sconstr
      } $ & $
      \inference{
        \sconstr \in \icEnv
      }{
        \cEnv ; \icEnv \solverRule \sconstr
      } $ \\ & & \\ \hline
    \end{tabularx}
  \caption{Base cases of the Solver's judgement}
  \label{fig:solver-base}
\end{figure}
\\
This recursive procedure may stop at a contradictory environment $\lightning$,
that short-cuircuts the procedure, or at
a state in which all the assumptions and goal itself are reduced to irreducible components,
which is then as simple as checking if the goal is trivial or if it
occurs on the left side of the turnstile.

\section{Goal-reducing rules}
\begin{figure}[htbp]
  \framebox[\textwidth]{
    % TODO: make this box nicer
    \centering
    \begin{tabular}{ccc}
      \\ $
      \inference{
      }{
        \cEnv ; \icEnv \solverRule \atomv = \atomv
      }
      $ & $
      \inference{
      }{
        \cEnv ; \icEnv \solverRule \termv = \termv
      }
      $ & $
      \inference{
      }{
        \cEnv ; \icEnv \solverRule \symb = \symb
      }
      $ \\ \\
      \multicolumn{3}{c}{ $
      \inference{
        \cEnv ; \icEnv \solverRule \term_1 = \term_2
        &
        \cEnv ; \icEnv \solverRule \term_1' = \term_2'
      }{
        \cEnv ; \icEnv \solverRule \term_1 \term_1' = \term_2 \term_2'
      }
      $ } \\ \\
      \multicolumn{3}{c}{ $
      \inference{
        \cEnv ; \icEnv \solverRule \atomexp_1 \cfresh \tbind{\atomexp_2}\term_2
        &
        \cEnv ; \icEnv \solverRule \term_1 = \permswap{\atomexp_1}{\atomexp_2} \term_2
      }{
        \cEnv ; \icEnv \solverRule \tbind{\atomexp_1} \term_1 = \tbind{\atomexp_2} \term_2
      }
      $ } \\ \\
      \end{tabular}
  }
  \caption{Equality-reduction rules}
  \label{fig:equality-reduction-rules}
\end{figure}
Checking equality of terms is rather straightforward and follows from the
term structure if no permutations are involved.
Only the case for abstraction terms is more involved:
the left side's argument must be fresh in the whole right side's term
(which informally means that either arguments are the same or
the left's argument doesn't occur at all in the right's body)
and that left body must be equal to the right body with if its argument was swapped for the left one.

To compare a \it{pure} atom $\atomv$ with permuted one, we employ the decidability of atom equality
to reduce the right hand-side's permutation by applying it's outermost swap $\permswap{\atomexp_1}{\atomexp_2}{}$ on the left side's atom.
There's three possible cases: \begin{enumerate}[noitemsep]
    \item $\atomv$ is different from both $\atomexp_1$ and $\atomexp_2$,
so the swap doesn't change the goal,
    \item $\atomv$ is equal to $\atomexp_1$ but different from $\atomexp_2$,
so the swap substitutes it for $\atomexp_2$,
    \item $\atomv$ is equal to $\atomexp_2$,
so the swap substitutes it for $\atomexp_1$.
\end{enumerate}
Notice that it is impossible for any two of these assumption to be valid at the same time
--- the contradictory branches will resolve through absurd environment.
\begin{figure}[htbp]
    \centering
    \begin{tabularx}{\textwidth}{|C|}
      \hline \\ $
      \inference{
        \atomv \cneq \atomexp_1, \atomv \cneq \atomexp_2, \cEnv ; \icEnv \solverRule \atomv     = \atomexp \\
        \atomv \ceq  \atomexp_1, \atomv \cneq \atomexp_2, \cEnv ; \icEnv \solverRule \atomexp_2 = \atomexp \\
        \atomv \ceq  \atomexp_2, \cEnv ; \icEnv \solverRule \atomexp_1 = \atomexp
      }{
        \cEnv ; \icEnv \solverRule \atomv = \permswap{\atomexp_1}{\atomexp_2}{\atomexp}
      }
      $ \\ \\
    \begin{tabular}{cc}
      $
      \inference{
        \cEnv ; \icEnv \solverRule \atomv = \perm^{-1} \atomexp
      }{
        \cEnv ; \icEnv \solverRule \perm \atomv = \atomexp
      }
      $ & $
      \inference{
        \cEnv ; \icEnv \solverRule \termv_1 = \pi_1^{-1} \pi_2 \termv_2
      }{
        \cEnv ; \icEnv \solverRule \pi_1 \termv_1 = \pi_2 \termv_2
      }
      $ \\ & \\
      $
      \inference{
        \cEnv ; \icEnv \solverRule \pi \text{ idempotent on } \termv
      }{
        \cEnv ; \icEnv \solverRule \termv = \pi \termv
      }
      $ & $
      \inference{
        \forall \atomv \in \pi.\;
          \cEnv ; \icEnv \solverRule \atomv = \pi \atomv \;\vee\;
          \cEnv ; \icEnv \solverRule \atomv \cfresh \termv
        }{
        \cEnv ; \icEnv \solverRule \pi \text{ idempotent on } \termv
      }
      $ \\ & \\
      $
      \permid ^ {-1} \;\term := \permid\;\term
      $ & $
      (\permswap{\atomexp_1}{\atomexp_2} \perm) ^ {-1} \;\term
        := \perm^{-1}(\permswap{\atomexp_1}{\atomexp_2} \;\term)
      $ \\ & \\
    \end{tabular} \\
    \hline
    \end{tabularx}
  \caption{Permutation-reduction rules}
  \label{fig:permutation-reduction-rules}
\end{figure}
\\
If the left-hand side's term is permuted we move the permutation
to the right-hand side by inverting it.
There's also special check for variables equal to their permuteded selves
--- we check whether that permutation is idempotent on them.

\begin{figure}[htbp]
    \centering
    \begin{tabularx}{\textwidth}{|C|}
      \hline \\
      \begin{tabular}{ccc}
      $
      \inference{
        \atomv_1 \cneq \atomv_2 \in \icEnv
      }{
        \cEnv ; \icEnv \solverRule \atomv_1 \cfresh \atomv_2
      }
      $ & $
      \inference{
        \atomv \cfresh \termv \in \icEnv
      }{
        \cEnv ; \icEnv \solverRule \atomv \cfresh \termv
      }
      $ & $
      \inference{
      }{
        \cEnv ; \icEnv \solverRule \atomv \cfresh \symb
      }
      $
      \end{tabular}
      \\ \\
      \begin{tabular}{cc}
      $
      \inference{
        \atomv \cneq \atomexp, \cEnv ; \icEnv \solverRule \atomv \cfresh \term
      }{
        \cEnv ; \icEnv \solverRule \atomv \cfresh \tbind{\atomexp}{\term}
      }
      $ &
      $
      \inference{
        \cEnv ; \icEnv \solverRule \atomv \cfresh \term_1
        &
        \cEnv ; \icEnv \solverRule \atomv \cfresh \term_2
      }{
        \cEnv ; \icEnv \solverRule \atomv \cfresh \term_1 \term_2
      }
      $
      \end{tabular}
      \\ \\ \hline
      \end{tabularx}
  \caption{Freshness-reduction rules}
  \label{fig:freshness-rules}
\end{figure}
Freshness follows the term structure and is using assumptions from $\icEnv$ environment.
Unlike to how we defined freshness in abstraction in the introduction,
we do not have two rules that differencing on whether $\atomv \ceq \atomexp$.
If they are indeed equal, then the assumption of inequality will immediately
result in contradiction of environment, but if it wasn't yet established
then we continue the solver procedure with an additional assumption.

\begin{figure}[htbp]
    \centering
    \begin{tabularx}{\textwidth}{|CC|}
      \hline & \\ $
      \inference{
      }{
        \cEnv ; \icEnv \solverRule \shatom \csheq \shatom
      }
      $ & $
      \inference{
      }{
        \cEnv ; \icEnv \solverRule \symb \csheq \symb
      }
      $ \\ & \\
      $
      \inference{
        \termv_1 \csheq \termv_2 \in \icEnv
      }{
        \cEnv ; \icEnv \solverRule \termv_1 \csheq \termv_2
      }
      $ & $
      \inference{
        \termv  \csheq \shape' \in \icEnv
        &
        \cEnv ; \icEnv \solverRule \shape'  \csheq \shape
      }{
        \cEnv ; \icEnv \solverRule \termv  \csheq \shape
      }
      $ \\ & \\
      $\inference{
        \cEnv ; \icEnv \solverRule \shape_1 \csheq \shape_2
      }{
        \cEnv ; \icEnv \solverRule \shbind \shape_1 \csheq \shbind \shape_2
      }
      $ & $
      \inference{
        \cEnv ; \icEnv \solverRule \shape_1 \csheq \shape_2
        &
        \cEnv ; \icEnv \solverRule \shape_1' \csheq \shape_2'
      }{
        \cEnv ; \icEnv \solverRule \shape_1 \shape_1' \csheq \shape_2 \shape_2'
      }
      $ \\ & \\ \hline
      \end{tabularx}
  \caption{Shape rules}
  \label{fig:shape-rules}
\end{figure}
Shape equality is naturally structural.
All atoms and only equal symbols are considered to have the same shape.
Variables can share shape and be have their shape stored by $\icEnv$,
which enables transitivity.

\begin{figure}[htbp]
    \centering
    \begin{tabularx}{\textwidth}{|CC|}
      \hline & \\ $
      \inference{
        \cEnv ; \icEnv \solverRule \shape_1 \csheq \shape_2
        &
        \shape_2 \cshlt \termv \in \icEnv
      }{
        \cEnv ; \icEnv \solverRule \shape_1 \cshlt \termv
      }
      $ & $
      \inference{
        \cEnv ; \icEnv \solverRule \shape_1 \cshlt \shape_2
        &
        \shape_2 \cshlt \termv \in \icEnv
      }{
        \cEnv ; \icEnv \solverRule \shape_1 \cshlt \termv
      }
      $ \\ & \\ \hline
      \end{tabularx}
  \caption{Subshape rules}
  \label{fig:subshape-rules}
\end{figure}
Solving subshape recurses through right-hand side shape's structure to find a shape-equal sub-shape.
Environment $\icEnv$ keeps track of all shapes that given variable subshapes,
enabling transitivity.

\begin{figure}[htbp]
    \centering
    \begin{tabularx}{\textwidth}{|CC|}
      \hline & \\ $
      \inference{
      }{
        \cEnv ; \icEnv \solverRule \csymb \symb
      }
      $ & $
      \inference{
        \csymb \termv \in \icEnv
      }{
        \cEnv ; \icEnv \solverRule \csymb \termv
      }
      $ \\ & \\ \hline
      \end{tabularx}
  \caption{Symbol rules}
  \label{fig:symbol-rules}
\end{figure}
Symbol constraints are really simple to check, either the term is already
a symbol, or it is a variable that we already assumed to be a symbol.

\section{Assumptions-reducing rules}
But before the Solver can reduce the goal-constraint, it must first reduce all assumptions in the $\cEnv$ environment.
We will now present the rules for reducing the left side of the turnstile,
but fortunately most of the assumption reducing rules are similar to the goal reducing analogues.

\begin{figure}[htpb]
  \centering
  \framebox[\textwidth]{
    \begin{tabularx}{\textwidth}{Cr}
      \\
      $
      \inference{
        \termv = \pi^{-1} \term, \cEnv ; \icEnv \solverRule \sconstr
      }{
        \pi \termv = \term, \cEnv ; \icEnv \solverRule \sconstr
      }
      \qquad
      \inference{
        \atomv \ceq \pi^{-1} \atomexp, \cEnv ; \icEnv \solverRule \sconstr
      }{
        \pi \atomv \ceq \atomexp, \cEnv ; \icEnv \solverRule \sconstr
      } $
      & \textsc{PermReduce} \\ \\
      $
      \inference{
        \pi \text{ idempotent on } \termv, \cEnv ; \icEnv \solverRule \sconstr
      }{
        \termv = \pi \termv, \cEnv ; \icEnv \solverRule \sconstr
      } $
      & \textsc{PermIdempotent} \\ \\
      $
      \inference{
        \varnothing \solverRule \text{ idempotent on } \termv
        &
        \cEnv ; \icEnv \solverRule \sconstr
      }{
        \pi \text{ idempotent on } \termv, \cEnv ; \icEnv \solverRule \sconstr
      } $
      & \textsc{PermShortcircuit} \\ \\
      $
      \inference{
        (\forall \atomv \in \pi.\;
          \cEnv ; \icEnv \solverRule \atomv = \pi \atomv \;\vee\;
          \cEnv ; \icEnv \solverRule \atomv \cfresh \termv), \cEnv ; \icEnv \solverRule \sconstr
      }{
        \pi \text{ idempotent on } \termv, \cEnv ; \icEnv \solverRule \sconstr
      } $
      & \textsc{PermExplode} \\ \\
    \end{tabularx}
  }
  \caption{Permutation-reducing rules}
  \label{fig:perm-reduction}
\end{figure}
For variables equal to some term and atoms equal to some atom expressions,
we first deal with permutation by inverting it and moving it to the right-hand side.
Then we consider the special case where a variable is equal to itself when permuted.
While the assumption of the permutation being idempotent might appear to multiply the number of assumptions exponentially based on the number of atoms in the given permutation,
it's worth noting that this number is unlikely to be very high, as permutations rarely consist of more than a few swaps.
In practice, the solver implementation will initially check whether the permutation is idempotent with an empty set of assumptions.
Only if this initial check fails, will it proceed to examine the permutation atom by atom.

Otherwise both equality and freshness assumptions follow from the term structure.
\begin{figure}[htpb]
  \centering
  \begin{tabularx}{\textwidth}{|CC|}
  \hline & \\ $
  \inference{
    \atomexp_1 \cfresh \tbind{\atomexp_2} \term_2\:,\;
      \term_1 = \permswap{\atomexp_1}{\atomexp_2}\term_2 \:, \;
      \cEnv ; \icEnv \solverRule \sconstr
  }{
    \tbind{\atomexp_1} \term_1 \ceq \tbind{\atomexp_2} \term_2 , \cEnv ; \icEnv \solverRule \sconstr
  } $ & $
  \inference{
    \atomv \ceq \atomexp, \; \cEnv ; \icEnv \solverRule \sconstr
    \\
    \atomv \cneq \atomexp, \; \atomv \cfresh \term,\;\cEnv ; \icEnv \solverRule \sconstr
  }{
    \atomv \cfresh \tbind{\atomexp} \term , \cEnv ; \icEnv \solverRule \sconstr
  } $ \\ & \\ \hline
  \end{tabularx}
  \caption{Abstraction assumption rules}
  \label{fig:abstraction}
\end{figure}
Consider the abstraction: equality behaves the same as on the goal side, we simply
split up the assumption into two assumptions the same way we would split the goal.
For freshness of an atom in an abstraction, we consider two cases:
either the atom is equal to the argument,
or different from the argument but fresh in the body.
In constrast to the goal-reducing rules where we would be satisifed with
just one branch successing, here we expect both possibilities to be satisfiable.

In the end, all assumptions reach the irreducible components that are handled through
the special environment $\icEnv$ enviroment.
\begin{figure}[htpb]
  \centering
  \framebox[\textwidth]{
    \begin{tabularx}{\textwidth}{Cr}
      \\ $
      \inference{
        \cEnv\subst{\termv}{\term} ; \icEnv\subst{\termv}{\term}
          \solverRule \sconstr\subst{\termv}{\term}
      }{
        \termv = \term, \cEnv ; \icEnv \solverRule \sconstr
      }$ & \textsc{SubstTerm} \\ \\
      $
      \inference{
        \cEnv \subst{\atomv_1}{\atomv_2}; \icEnv\subst{\atomv_1}{\atomv_2}
          \solverRule \sconstr\subst{\atomv_1}{\atomv_2}
      }{
        \atomv_1 \ceq \atomv_2, \cEnv ; \icEnv \solverRule \sconstr
      } $ & \textsc{SubstAtom} \\ \\
    \end{tabularx}
  }
  \caption{Substitution rules}
  \label{fig:substitution}
\end{figure}
Equality assumptions reduce to substitution of the name for the expression,
and while substitution over the environment $\cEnv$ and goal $\sconstr$ is indeed a simple substitution, substituting in $\icEnv$ environment is a more involved process
that can can arrive at a contradiction.
Otherwise assumption are simply moved to the environment of irreducible
constraints via procedure that we describe in the next section.
\begin{figure}[htpb]
  \centering
    \begin{tabularx}{\textwidth}{|CC|}
    \hline & \\ $
    \inference{
      \cEnv ; \{\atomv_1 \cneq \atomv_2\} \cup \icEnv \solverRule \sconstr
    }{
      \atomv_1 \cneq \atomv_2, \; \cEnv ; \icEnv \solverRule \sconstr
    }
    $ & $
    \inference{
      \cEnv ; \{\atomv \cfresh \termv\} \cup \icEnv \solverRule \sconstr
    }{
      \atomv \cfresh \termv, \; \cEnv ; \icEnv \solverRule \sconstr
    }
    $ \\ & \\ $
    \inference{
      \cEnv ; \{\termv_1 \csheq \termv_2\} \cup \icEnv \vDash \sconstr
    }{
      \termv_1 \csheq \termv_2, \cEnv ; \icEnv \vDash \sconstr
    }
    $ & $
    \inference{
      \cEnv ; \{\termv \csheq \shape\} \cup \icEnv \vDash \sconstr
    }{
      \termv \csheq \shape,\; \cEnv ; \icEnv \vDash \sconstr
    }
    \quad
    $ \\ & \\ $
    \inference{
      \cEnv ; \{\term \cshlt \termv\} \cup \icEnv \vDash \sconstr
    }{
      \term \cshlt \termv, \cEnv ; \icEnv \vDash \sconstr
    }
    $ & $
    \inference{
      \cEnv ; \{\csymb \termv\} \cup \icEnv \vDash \sconstr
    }{
      \csymb \termv, \cEnv ; \icEnv \vDash \sconstr
    }
    $ \\ & \\ \hline
    \end{tabularx}
  \caption{Moving irreducible assumptions inside $\icEnv$}
  \label{fig:assumption-equality-rules}
\end{figure}

\section{Irreducible constraints} \label{sec:solverenv}
Environment $\icEnv$ that containts all the irreducible assumptions is given by
a sextuple
$(\NeqAtoms_{\icEnv}
, \Fresh_{\icEnv}
, \VarShape_{\icEnv}
, \Shape_{\icEnv}
, \Subshape_{\icEnv}
, \Symbols{\icEnv}
)$.
\begin{figure}[htpb]
  \begin{tabularx}{\textwidth}{|l|X|}
  \hline
    $\NeqAtoms$ & Set of pairs of atoms that are known to be different. \\
  \hline
    $\Fresh$ & Set of pairs of atom and variable, indicating that the atom is \it{fresh} in the variable. \\
  \hline
    $\VarShape$ & Mapping from variables to shape-representative variables. All variables mapped to the same representative are considered to inhabit the same shape. \\
  \hline
    $\Shape$ & Mapping from shape-representative variables to the actual shape it must inhabit. \\
  \hline
    $\Subshape$ & Set of pairs of shape-representative variables and
    shapes that subshape the variable. \\
  \hline
    $\Symbols$ & Set of shape-representative variables that are known to be some unknown functional symbols. \\
  \hline
  \end{tabularx}
  \caption{Description of environment $\icEnv$}
  \label{fig:assumption-equality-rules}
\end{figure}

We can now establish a method to compute the shape-representative variable and
outline the procedure for reconstructing the shape within the environment $\icEnv$:\\

\begin{figure}[htbp]
    \begin{tabular}{|p{0.55\textwidth}p{0.39\textwidth}|}
        \hline
      \begin{lstlisting}[mathescape, language=OCaml]
    $\shrep{\termv} :=$
      | if $Y$ $\leftarrow\;$var_shape$_\icEnv$ $\termv$ then $\shrep{Y}$
      | otherwise $\termv$

    $\shenv{\termv} :=$
      | if $Y$ $\leftarrow\;$var_shape$_\icEnv$ $\termv$ then $\shenv{Y}$
      | if $\shape$ $\leftarrow\;$shape$_\icEnv$ $\termv$ then $\shape$
      | otherwise $\termv$
        \end{lstlisting}
        &
        \begin{lstlisting}[mathescape, language=OCaml]

  $\shenv{\shatom}          $ $\;$  $:=$ $\shatom $
  $\shenv{\shbind \shape}   $ $$ $:=$ $\shbind \shenv{\shape} $
  $\shenv{\shape_1 \shape_2}$ $:=$ $\shenv{\shape_1} \shenv{\shape_2}$
  $\shenv{\symb}            $  $$  $:=$ $\symb $
  $\shenv{\term}            $ $$  $\;\:\: :=$ $\shenv{|\term|}$
      \end{lstlisting} \\
      \hline
    \end{tabular}
  \caption{Shape interpretation in $\icEnv$}
  \label{fig:shape-interpretation}
\end{figure}

Then, verifying whether a constraint is included in $\icEnv$ can be accomplished straightforwardly:
\begin{figure}[htbp]
  \centering
  \begin{tabularx}{\textwidth}{|XrclX|}
  \hline & & & & \\
  & $(\atomv_1 \cneq \atomv_2) \in \icEnv $ & $:=$ & $ (\atomv_1 \cneq \atomv_2) \in \NeqAtoms_{\icEnv} $ & \\
  & $(\atomv \cfresh \termv) \in \icEnv $ & $:=$ & $ \termv \in \Fresh_{\icEnv}(\atomv) $ & \\
  & $(\termv_1 \csheq \termv_2) \in \icEnv $ & $:=$ & $ \shenv{\termv_1} \ceq \shenv{\termv_2} $ & \\
  & $(\termv \csheq \shape) \in \icEnv $ & $:=$ & $ \shape = \Shape_{\icEnv}(\shrep{\termv})$ & \\
  & $(\shape \cshlt \termv) \in \icEnv $ & $:=$ & $ \shape \in \Subshape_{\icEnv}(\shrep{\termv})$ & \\ & & & & \\
  \hline
\end{tabularx}
  \caption{Assumptions interpretation in $\icEnv$}
  \label{fig:assumptions-interpretation}
\end{figure}
And establish rules for a special occurs check procedure,
which safeguards against handling circular references,
and does so while considering all occurences in the assumptions of $\icEnv$.

\begin{figure}[htbp]
  \centering
  \framebox[\textwidth]{
    \begin{tabularx}{\textwidth}{C}
    \\ $
    \inference{
      \stxoccurs{\shrep{\termv}}{\shenv{\shape}}
    }{
      \icEnv \solverRule \occurs{\termv}{\shape}
    }
    $ \\ \\
    $
    \inference{
      \stxoccurs{\termv'}{\shenv{\shape}}
      \\
        (\shape' \cshlt \termv') \in \icEnv
        &
        \icEnv \solverRule \occurs{\termv}{\shape'}
    }{
      \icEnv \solverRule \occurs{\termv}{\shape}
    }
    $ \\ \\
    \end{tabularx}
  }
  \caption{Occurs check rules}
  \label{fig:subkinding-rules}
\end{figure}

Incorporating constraints into $\icEnv$ proceeds as follows:
freshness of an atom in a in a variables is simply acknowledged in the $\Fresh$ mapping.
Inequality of two atoms simply adds to the set $\NeqAtoms$,
unless invoked with identical atoms, in which case we report a contradiction.
We are using OCaml's pipelining notation of \lstinline[mathescape, language=OCaml]{x |> f1 |> ... |> fn}
for \lstinline[mathescape, language=OCaml]{fn (... (f1 x))}
and treat expressions like \lstinline[mathescape, language=OCaml]{fresh += x}
as functions, meaning
\lstinline[mathescape, language=OCaml] {fun $\icEnv$ -> $\{$ $\icEnv$ with fresh = x :: $\icEnv$.fresh $\}$}
and alike.
\begin{figure}[htbp]
    \begin{tabular}{|p{0.95\textwidth}|}
        \hline
      \begin{lstlisting}[mathescape, language=OCaml]
    $\{\atomv \cfresh \termv\} \cup \icEnv :=$
      $\icEnv\;$ |> fresh += ($\atomv \cfresh \termv$)

    $\{\atomv \cneq \atomv'\} \cup \icEnv :=$
      | if $\atomv \ceq \atomv'$ then $\lightning$
      | otherwise $\icEnv\;$|> neq_atoms += ($\atomv \cneq \atomv'$)


    $\{\termv \csheq \termv'\} \cup \icEnv :=$
      | if $\shrep{\termv} \ceq \shrep{\termv'}$ then $\icEnv$
      | if $\shenv{\termv} \ceq \shenv{\termv'}$ then $\icEnv$
      | if $\occurs{\shrep{\termv}}{\shenv{\termv'}}$ then $\lightning$
      | if $\occurs{\shrep{\termv'}}{\shenv{\termv}}$ then $\lightning$
      | otherwise $\icEnv\;$|> symbols        $\{\shrep{\termv} \leadsto \shrep{\termv'}\}$
                    |> subshape       $\{\shrep{\termv} \leadsto \shrep{\termv'}\}$
                    |> transfer_shape $\{\shrep{\termv} \leadsto \shrep{\termv'}\}$
                    |> var_shape += $(\shrep\termv \mapsto \shrep\termv')$
                    |> shape     -= $\shrep\termv$
                    |> subshape  -= $\shrep\termv$

    $\{\termv \csheq \shape\} \cup \icEnv :=$
      | if $\occurs{\shrep{\termv}}{\shenv{\shape}}$ then $\lightning$
      | otherwise $\icEnv\;$|> symbols  $\{\shrep{\termv} \leadsto \shenv{\shape}\}$
                    |> subshape $\{\shrep{\termv} \leadsto \shenv{\shape}\}$
                    |> shape    $\{\shrep{\termv} \leadsto \shenv{\shape}\}$
\end{lstlisting} \\
      \hline
    \end{tabular}
  \caption{Adding constraints to $\icEnv$}
  \label{fig:adding-constraints}
\end{figure}

\begin{figure}[htbp]
    \begin{tabular}{|p{0.95\textwidth}|}
        \hline
      \begin{lstlisting}[mathescape, language=OCaml]
    $\icEnv$ $\{\termv \mapsto \term\}$ $:=$
      $\icEnv\;$|> fresh -= $\termv$
        |> assumptions += $(\termv \csheq \shenv{\term})$
        |> assumptions += $\bigcup_{(\atomv \cfresh \termv) \in \icEnv} (\atomv \cfresh \term)$

    $\icEnv$ $\{\atomv \mapsto \atomv'\}$ $:=$
      $\icEnv\;$|> fresh -= $\atomv$
        |> fresh += $(\atomv' \cfresh{}$fresh$_\icEnv$$\atomv)$
        |> clear neq_atoms
        |> assumptions += $\bigcup_{(\atomv_1 \cneq \atomv_2) \in \icEnv} (\atomv_1\{\atomv \mapsto \atomv'\} \cneq \atomv_2\{\atomv \mapsto \atomv'\})$
\end{lstlisting} \\
      \hline
    \end{tabular}
  \caption{Substitution in $\icEnv$}
  \label{fig:substitution}
\end{figure}

To meld together two shape-variables, we first check whether they have already been merged.
If they have, we return contradiction.
\\
Next, we conduct an occurs check to ensure that merging them won't create a circular reference. If this check fails, we again report a contradiction.
\\
Finally, we merge all the information pertaining to $\termv$ into $\termv'$ and
remove any traces of $\termv$ from within $\icEnv$ environment.
\\
To maintain a high-level description, we delegate the detailed implementation aspects to auxiliary functions responsible for substituting shape-variables within the given field of $\icEnv$.

To set variable shape, we first make sure to perform occurs check on the proposed shape
and then substitute the shape-variable in all affected fields.

Note that we are using the meta-field of $\Assumptions$ to indicate that some of the
assumptions in $\icEnv$ are no longer "simple" and escape from $\icEnv$ back to
$\cEnv$ to be broken up by the \it{Solver}.\begin{figure}[htbp]
    \begin{tabular}{|p{0.95\textwidth}|}
        \hline
      \begin{lstlisting}[mathescape, language=OCaml]
    symbols $\{\termv \leadsto \shape\}$ $\icEnv$ $:=$
      | if $\shrep{\termv} \notin$ symbols$_\icEnv$ then $\icEnv$
      | otherwise $\icEnv\;$|> symbols -= $\termv$
                    |> assumptions += ($\textnormal{symbol } \shape$)

    shape $\{\termv \leadsto \shape\}$ $\icEnv$ $:=$
      | if $\shape' \leftarrow\;$shape$_\icEnv$ $\termv$ then $\icEnv$ |> assumptions += $(\shape \csheq \shape')$
      | otherwise $\icEnv\;$|> shapes += $(\termv \mapsto \shape)$

    subshape $\{\termv \leadsto \shape\}$ $\icEnv$ $:=$
      $\icEnv\;$|> assumptions += $($subshapes$_\icEnv \termv \cshlt \shape)$

    transfer_shape $\{\termv \leadsto \termv'\}$ $\icEnv$ $:=$
      | if $\shape \leftarrow\;$shape$_\icEnv$ $\termv$ then $\icEnv$ |> shape $\{\termv' \leadsto \shape\}$
      | otherwise $\icEnv$
\end{lstlisting} \\
      \hline
    \end{tabular}
  \caption{Auxiliary functions in $\icEnv$}
  \label{fig:solverenv-auxiliary}
\end{figure}
Finally, we demonstrate how the substitution of variables and atoms is accomplished,
thereby concluding the description of the \it{Solver} and its environment.

And that finishes the Solver description.
Now the curious reader should feel obliged to ask themselves an important question:
does that procedure always stop?

To address this question, we define the state of the Solver as a triple $(\cEnv, \icEnv, \sconstr)$.
Upon analyzing the Solver rules, it becomes evident that each rule consistently
leads to a lesser state by reducing it through one or more of the following actions:
\begin{enumerate}[noitemsep]
  \item Decreasing the number of distinct variables in $\cEnv$, $\icEnv$, and $\sconstr$,
  or maintaining the same number while:
  \item Decreasing the depth of $\sconstr$,
  or preserving the current depth while:
  \item Reducing assumptions with a given depth in either $\cEnv$ or $\icEnv$ into assumptions with lower depth,
  or maintaining the number and depth of assumptions, while:
  \item Eliminating an assumption from $\cEnv$ and introducing an assumption of the same depth into $\icEnv$.
\end{enumerate}

In the following chapters, we will write $\cEnv \vDash \constr$
but mean $\cEnv ; \emptyset \solverRule \sconstr$,
as by the construction of $\solverRule$ we consider it equivalent
to $\vDash$ defined in the model.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Higher Order Logic}
On top of the sublogic of constraints, we build a higher-order logic.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Kinds}
We introduce kinds to ensure that the formulas we will deal with
are \it{making sense},
due to the multiple ways atoms, terms, binders, and constraints can occur in them.
\begin{figure}[htbp]
  \framebox[\textwidth]{
\begin{tabularx}{\textwidth}{rcl@{\extracolsep{\fill}}r}
$\kind$ & $::=$ & $\kProp
            \bnfor \kind \karrow \kind
            \bnfor \kForallAtom{\atomv} \kind
            \bnfor \kForallTerm{\termv} \kind
            \bnfor \kGuard{\constr} \kind$
    & (kinds) \\
\end{tabularx}
  }
  \caption{Kinds grammar}
  \label{fig:kinds-grammar}
\end{figure}
\\
Notice that as constraints occur in kinds, we cannot simply give functions
from atoms some kind ${Atom}\karrow\kind$, but we must know \it{which} atom
is bound there, to substitute for it in $\kind$ the same way we substitute
that atom for an atom expression in the function body when applying it to the formula.
The \it{guarded kind} $\kGuard{\constr} \kind$ is most importantly used in
kinding of the fixpoint formulas, which we will explain in later sections.
\begin{figure}[htbp]
\begin{tabularx}{\textwidth}{|l|X|}
\hline
$\formphi \ofkind \kProp$ & $\formphi$ is a propositional formula.
\\ \hline
$\formphi \ofkind \kind_1 \karrow \kind_2$ & \makecell[l]{$\formphi$ is a function that takes a formula of kind $\kind_1$, \\ and produces a formula of kind $\kind_2$.}
\\ \hline
$\formphi \ofkind \kForallAtom{\atomv} \kind$ & \makecell[l]{$\formphi$ is a function that takes an atom expression, binds it to $\atomv$, \\ and produces a formula of kind $\kind$.}
\\ \hline
$\formphi \ofkind \kForallTerm{\termv} \kind$ & \makecell[l]{$\formphi$ is a function that takes a term, binds it to $\termv$, \\ and produces a formula of kind $\kind$.}
\\ \hline
$\formphi \ofkind \kGuard{\constr} \kind$ & \makecell[l]{$\formphi$ is a formula of kind $\kind$ as long as $\constr$ is satisfied.}
\\ \hline
\end{tabularx}
  \caption{Kinds semantics}
  \label{fig:kinds-semantics}
\end{figure}

\section{Subkinding}
We relax kinding rules are through the \it{subkinding} relation.
\begin{figure}[htbp]
  \centering
  \framebox[\textwidth]{
    \setlength{\extrarowheight}{20pt} % Adjust the space between lines
    \begin{tabularx}{\textwidth}{C}
        $\inference[\textsc{SubkindRefl}]{
        }{
          \cEnv \vdash \kind \subkind \kind
        }
        \qquad
        \inference[\textsc{SubkindTrans}]{
          \cEnv \vdash \kind_1 \subkind \kind_2 &
          \cEnv \vdash \kind_2 \subkind \kind_3
        }{
          \cEnv \vdash \kind_1 \subkind \kind_3
        }$ \\
        $\inference[\textsc{SubkindForallAtom}]{
          \cEnv \vdash \kind_1 \subkind \kind_2
        }{
          \cEnv \vdash \kForallAtom{\atomv} \kind_1 \subkind \kForallAtom{\atomv} \kind_2
        }$ \\
        $\inference[\textsc{SubkindForallTerm}]{
          \cEnv \vdash \kind_1 \subkind \kind_2
        }{
          \cEnv \vdash \kForallTerm{\termv} \kind_1 \subkind \kForallTerm{\termv} \kind_2
        }$ \\
        $\inference[\textsc{SubkindFunction}]{
          \cEnv \vdash \kind_1' \subkind \kind_1 &
          \cEnv \vdash \kind_2 \subkind \kind_2'
        }{
          \cEnv \vdash \kind_1 \karrow \kind_2 \subkind \kind_1' \karrow \kind_2'
        }$ \\
        $\inference[\textsc{SubkindReduce}]{
          \cEnv \vDash \constr
        }{
          \cEnv \vdash \kGuard{\constr}\kind \subkind \kind
        }
        \qquad
        \inference[\textsc{SubkindGuard}]{
          \cEnv, \constr \vdash \kind_1 \subkind \kind_2
        }{
          \cEnv \vdash \kind_1 \subkind \kGuard{\constr}\kind_2
        }$
    \end{tabularx}
  }
  \caption{Subkinding Rules}
  \label{fig:subkinding-rules}
\end{figure}

Function kind is contravariant to the subkinding relation on the left argument:
Universally quantified kinds only subkind if they are quantified over the same name.
Constraints from the left side that are solved through $\vDash$ relation can be dropped,
and constraints from the right-hand side can be moved inside of the enviroment.
$$
\inference{\cEnv \vdash \kind_1 \subkind \kind_2}{
  \cEnv \vdash \kGuard{\constr} \kind_1 \subkind \kGuard{\constr} \kind_2
  }
  $$
Note that there is no structural subkinding rule for guarded kinds like
the one above, but such a rule can be derived from \textsc{SubkindReduce}, \textsc{SubkindGuard}, transitivity, and weakening.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Formulas}
Formulas include standard connectives (of kind $\kProp$):

\begin{tabular}{rrlr}
$\formphi$ & $::=$ & $\bot
               \bnfor \top
               \bnfor \formphi \vee \formphi
               \bnfor \formphi \wedge \formphi
               \bnfor \formphi \fImp \formphi
               \bnfor \ldots $ & (formulas)
\end{tabular}
\\ \\
Quantification over atoms and terms (on formulas of kind $\kProp$):

\begin{tabular}{rrlr}
$\formphi$ & $::=$ & $\ldots
               \bnfor \fForallAtom{\atomv} \formphi
               \bnfor \fForallTerm{\termv} \formphi
               \bnfor \fExistsAtom{\atomv} \formphi
               \bnfor \fExistsTerm{\termv} \formphi
               \bnfor \ldots$
    & (formulas)
\end{tabular}
\\ \\
Constraints and guards:

\begin{tabular}{rrlr}
$\formphi$ & $::=$ & $\ldots
               \bnfor \fConstr{\constr}
               \bnfor \fCAnd{\constr} \formphi
               \bnfor \fCImp{\constr} \formphi
               \bnfor \ldots$  (formulas)
\end{tabular}

\begin{figure}[htbp]
  \centering
\begin{tabularx}{\textwidth}{|CCC|}
\hline & & \\ $
  \inference{
  }{
    \cEnv; \kEnv \vdash \fConstr{\constr} \ofkind \kProp
  }
  $ & $
  \inference{
    \cEnv,\constr; \kEnv \vdash \formphi \ofkind \kProp
  }{
    \cEnv; \kEnv \vdash \fCAnd{\constr} \formphi \ofkind \kProp
  }
  $ & $
  \inference{
    \cEnv,\constr; \kEnv \vdash \formphi \ofkind \kProp
  }{
    \cEnv; \kEnv \vdash \fCImp{\constr} \formphi \ofkind \kProp
  } $ \\ & & \\
\hline
\end{tabularx}
  \caption{Constraint kinding rules}
  \label{fig:constraint-kinding}
\end{figure}

Naturally, constraints can act as propositions, as we can reason about their
validity, and thus they are of kind $\kProp$.
Constructions $\fCImp{\constr} \formphi$ and $\fCAnd{\constr} \formphi$
are called \it{guards} and make assumptions about the environment in which
one shall interpret the guarded formula.
The former states that the formula $\formphi$ holds if the constraint $\constr$ is valid,
analogously to a propositional implication.
The latter additionaly requires that $\constr$ already holds.

TODO: Write why not simply use propositional implication and conjunction (kinding example?)

Next: propositional variables, functions and applications:

\begin{tabular}{rrlr}
$\formphi$ & $::=$ & $\ldots
               \bnfor \propv
               \bnfor \fLamAtom{\atomv} \formphi
               \bnfor \fLamTerm{\termv} \formphi
               \bnfor \fLamForm{\propv}{\kind} \formphi
               \bnfor \formphi \fAppAtom{\atomexp}
               \bnfor \formphi \fAppTerm{\term}
               \bnfor \formphi \fApp \formphi
               \bnfor \ldots$
    & (formulas)
\end{tabular}\\
\begin{figure}[htpb]
  \begin{tabularx}{\textwidth}{|CC|}
    \hline & \\
    $\inference{
      \cEnv; \kEnv \vdash \formphi \ofkind \kind
    }{
      \cEnv; \kEnv \vdash \fLamAtom{\atomv} \formphi \ofkind \kForallAtom{\atomv}\kind
    }$
    &
    $\inference{
      \cEnv;\kEnv\vdash \formphi \ofkind \kForallAtom{\atomv}\kind
    }{
      \cEnv;\kEnv\vdash \formphi \fAppAtom{\atomexp} \ofkind \kind \subst{\atomv}{\atomexp}
    }$
    \\ & \\
    $\inference{
      \cEnv; \kEnv \vdash \formphi \ofkind \kind
    }{
      \cEnv; \kEnv \vdash \fLamTerm{\termv} \formphi \ofkind \kForallTerm{\termv}\kind
    }$
    &
    $\inference{
      \cEnv;\kEnv\vdash \formphi \ofkind \kForallTerm{\termv}\kind
    }{
      \cEnv;\kEnv\vdash \formphi \fAppTerm{\term} \ofkind \kind\subst{\termv}{\term}
    }$
    \\ & \\
    $\inference{
      \cEnv; \kEnv, \propv \ofkind \kind_1 \vdash \formphi \ofkind \kind_2
    }{
      \cEnv; \kEnv \vdash \fLamForm{\propv}{\kind_1} \formphi \ofkind \kind_1 \karrow \kind_2
    }$
    &
    $\inference{
      \cEnv; \kEnv \vdash \formphi_1 \ofkind \kind' \karrow \kind
      \\
      \cEnv; \kEnv \vdash \formphi_2 \ofkind \kind'
    }{
      \cEnv;\kEnv\vdash \formphi_1 \fApp \formphi_2 \ofkind \kind
    }$
    \\ & \\
    \hline
\end{tabularx}
  \caption{Function kinding rules}
  \label{fig:function-kinding}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Fixpoint}
And finish the definition of formulas with \it{fixpoint} function:
\\
\begin{tabular}{rrlr}
$\formphi$ & $::=$ & $\ldots
               \bnfor \fix{\propv}{\termv}{\kind}{\formphi} $
    & (formulas)
\end{tabular}

\begin{figure}[htpb]
  \begin{tabularx}{\textwidth}{|C|}
    \hline \\ $
\inference{
  \cEnv;\kEnv, (\propv \ofkind \kForallTerm{Y} \kGuard{Y \cshlt \termv}{\kind\subst{\termv}{Y}})\vdash \formphi \ofkind \kind
}{
  \cEnv;\kEnv\vdash (\fix{\propv}{\termv}{\kind}{\formphi}) \ofkind \kForallTerm{\termv}{\kind}
}
  $ \\ \\
  $
(\fix{\propv}{\termv}{\kind}{\formphi})\fApp\term
\;\equiv\;
\formphi\subst{\termv}{\term}\subst{\propv}{(\fix{\propv}{\termv}{\kind}{\formphi})}
$
  \\ \\ \hline
\end{tabularx}
  \caption{Fixpoint kinding rule}
  \label{fig:fixpoint-kinding}
\end{figure}
The fixpoint constructor allows us to express \it{recursive} predicates over terms,
but only such that the recursive applications of it are on structurally smaller terms,
which we express in it's kinding rule, through the kinding $(\propv \ofkind \kForallTerm{Y} \kGuard{Y \cshlt \termv}{\;\kind\subst{\termv}{Y}})$.
To evaluate a fixpoint function applied to a term, simply substitute the bound
variable with the given term and replace recursive calls inside the fixpoint's body with the fixpoint itself.
Because the applied term is finite
and we always recurse on structurally smaller terms,
the final formula after all substitutions must also be finite
--— thanks to the semantics of constraints and kinds.

To familiarize the reader with the fixpoint formulas,
we present how Peano arithmetic can be modeled in our logic.
Given symbols $0$ and $S$ for natural number construction,
one can write a predicate $({Nat}\fAppTerm{N})$
that a term $N$ models some natural number,
and $({PlusEq}\fAppTerm{N}\fAppTerm{M}\fAppTerm{K})$ that
two terms $N$ and $M$ added together are equal to $K$.
\begin{figure}[htpb]
  \begin{tabularx}{\textwidth}{|X|}
    \hline \\ $
\text{ }\qquad\fix{Nat}{N}{\kProp}{(N \ceq 0) \vee (\fExistsTerm{M} \fCAnd{N \ceq {S \tapp M}} ({Nat}\fAppTerm{M}))}
$ \\ \\
  $\text{ }\qquad\fix{PlusEq}{N}{\kForallTerm{M}\kForallTerm{K}\kProp}{\fLamTerm{M}\fLamTerm{K}}$ \\
  $\text{ }\qquad\qquad
  (\fCAnd{N \ceq 0}{(M \ceq K)}) \;\vee\; $
  \\
  $\text{ }\qquad\qquad\quad
   (\fExistsTerm{N', K'}\fCAnd{N \ceq {S \tapp N'}}\fCAnd{K \ceq {S \tapp K'}}{({PlusEq}\fApp{N'}\fApp{M}\fApp{K'})}
   )
$
  \\ \\ \hline
\end{tabularx}
  \caption{Peano arithmetic expressed with fixpoint}
  \label{fig:peano-fixpoint}
\end{figure}

Notice how the constraint $(N \ceq {S \tapp M})$ guards the recursive call to $Nat$,
ensuring that constraint $(M \cshlt N)$ will be satisfied during kind checking of
$({{Nat}\fAppTerm{M}})$ in the kind derivation of the whole formula
$({Nat} \ofkind \kForallTerm{N}{\kProp})$, analosly in $PlusEq$.

TODO: Write how $N$ is treated differently from $M$ and $K$?
\\
See more interesting examples of fixpoints usage in the chapter on STLC.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Natural deduction}

\newcommand{\rel}[2][\Gamma;C]{\ensuremath{#1\vdash#2}}
\newcommand{\types}[3][\Gamma]{\rel[#1]{#2 : #3}}
\newcommand{\interp}[2][\tmEnv]{\left\llbracket {#2} \right\rrbracket_{#1}}
\newcommand{\arr}{\rightarrow }
% \newcommand{\inference}[2]{\inference{ #1}{#2}}
\newcommand{\all}[1][x]{\ensuremath{\forall #1.\:}}
\newcommand{\exi}[1][x]{\ensuremath{\exists #1.\:}}
\newcommand{\karr}{\Rightarrow }
\newcommand{\lam}[1][x]{\lambda{#1}.\;}
\newcommand{\jgmnt[2]}[\cEnv;\Theta]{\ensuremath{#1 \vdash #2}}
\newcommand{\cjgmnt[2]}[\cEnv]{\ensuremath{#1 \vDash #2}}
\newcommand{\fv[1]}[\cEnv;\Theta]{\ensuremath{\operatorname{FV}(#1)}}

Finally, we come to the definition of proof-theoretic rules.
Starting with inference rules for assumption,
we can see first an analogue between the worlds of propositional logic
and constraint sublogic.
And while the $\vdash$ relation we define is purely syntactic,
we can still use semantic $\vDash$ because of its decidability and equivalence
to our description from \hyperref[sec:solver]{the chapter about the Solver}.

Again, for \it{ex falso}, we define an analogous proof constructor for dealing with a contradictory
constraint environment.
Note that there are many constraints that can be used as $\bot_\constr$, i.e.
constraints that are always false, and the solver will only \it{prove} them
if we supply it with contradictory assumptions.

Inference rules for implication are standard, and the reason we present them here
is not to bore the reader, but to point out the similarities to their constraint analogues.

Notice that in the case of constraint-and-guard, the rule for elimination is restricted
to only formulas of kind $\kProp$.
This is due to the nature of the guard --- if we want to eliminate it,
we can only do so with formulas that \it{make sense} on their own,
without that $\constr$ guard.

\begin{figure}[htbp]
  \centering
  \begin{tabular}{|c|}
  \hline \\
  $
  \inference{
    \formphi \in \Theta
  }{
    \jgmnt[\cEnv;\Theta]{\formphi}
  }[(\ensuremath{Assumption})]
  \qquad
  \inference{
    \cjgmnt[\cEnv]{\constr}
  }{
    \jgmnt[\cEnv;\Theta]{\constr}
  }[(\ensuremath{constr^i})]
  $ \\ \\ $
  \inference{
    \jgmnt[\cEnv;\Theta]{\bot}
  }{
    \jgmnt[\cEnv;\Theta]{\formphi}
  }[(\ensuremath{\bot^e})]
  \qquad
  \inference{
    \cjgmnt[\cEnv]{\bot_\constr}
    }{
    \jgmnt[\cEnv;\Theta]{\formphi}
  }[(\ensuremath{constr^e})]
  $ \\ \\ $
  \inference{
    \jgmnt[\cEnv;\Theta,\formphi_1]{\formphi_2}
  }{
    \jgmnt[\cEnv;\Theta]{\formphi_1 \fImp \formphi_2}
  }[(\ensuremath{\fImp^i})]
  \qquad
  \inference{
    \jgmnt[\cEnv_1;\Theta_1]{\formphi_1} &
    \jgmnt[\cEnv_2;\Theta_2]{\formphi_1 \fImp \formphi_2}
    }{
    \jgmnt[\cEnv_1 \cup \cEnv_2;\Theta_2 \cup \Theta_2]{\formphi_2}
  }[(\ensuremath{\fImp^e})]
  $ \\ \\ $
  \inference{
    \jgmnt[\cEnv, \constr;\Theta]{\formphi}
  }{
    \jgmnt[\cEnv;\Theta]{\fCImp{\constr}\formphi}
  }[(\ensuremath{\fCImp{\cdot}^i})]
  \qquad
  \inference{
    \jgmnt[\cEnv_1;\Theta_1]{\constr} &
    \jgmnt[\cEnv_2;\Theta_2]{\fCImp{\constr}\formphi}
    }{
    \jgmnt[\cEnv_1 \cup \cEnv_2;\Theta_2 \cup \Theta_2]{\formphi}
  }[(\ensuremath{\fCImp{\cdot}^e})]
  $ \\ \\ $
  \inference{
    \jgmnt[\cEnv_1;\Theta_1]{\formphi_1} &
    \jgmnt[\cEnv_2;\Theta_2]{\formphi_2}
  }{
    \jgmnt[\cEnv_1 \cup \cEnv_2;\Theta_2 \cup \Theta_2]{\formphi_1 \wedge \formphi_2}
  }[(\ensuremath{\wedge^i})]
  \qquad
  \inference{
    \jgmnt[\cEnv;\Theta]{\formphi_1 \wedge \formphi_2}
    }{
    \jgmnt[\cEnv;\Theta]{\formphi_1}
  }[(\ensuremath{\wedge^e_1})]\qquad
  \inference{
    \jgmnt[\cEnv;\Theta]{\formphi_1 \wedge \formphi_2}
    }{
    \jgmnt[\cEnv;\Theta]{\formphi_2}
  }[(\ensuremath{\wedge^e_2})]
  $ \\ \\ $
  \inference{
    \cjgmnt[\cEnv]{\constr} &
    \jgmnt[\cEnv, \constr;\Theta]{\formphi}
  }{
    \jgmnt[\cEnv;\Theta]{\fCAnd{\constr}\formphi}
  }[(\ensuremath{\fCAnd{\cdot}^i})]
  \qquad
  \inference{
    \jgmnt[\cEnv;\Theta]{\fCAnd{\constr}\formphi}
    }{
    \jgmnt[\cEnv;\Theta]{\constr}
  }[(\ensuremath{\fCAnd{\cdot}^e_1})]\qquad
  \inference{
    \jgmnt[\cEnv]{\fCAnd{\constr}\formphi} &
    \jgmnt[\cEnv;\Theta]{\formphi: \kProp}
    }{
    \jgmnt[\cEnv;\Theta]{\formphi}
  }[(\ensuremath{\fCAnd{\cdot}^e_2})]
  $ \\ \\ $
  \inference{
    \jgmnt[\cEnv;\Theta]{\formphi_1}
    }{
    \jgmnt[\cEnv;\Theta]{\formphi_1 \vee \formphi_2}
  }[(\ensuremath{\vee^i_1})]
  \qquad
  \inference{
    \jgmnt[\cEnv;\Theta]{\formphi_2}
  }{
    \jgmnt[\cEnv;\Theta]{\formphi_1 \vee \formphi_2}
  }[(\ensuremath{\vee^i_2})]
  \qquad
  \inference{
    \jgmnt[\cEnv;\Theta]{\formphi_1 \vee \formphi_2} \\
    \jgmnt[\cEnv;\Theta,\formphi_1]{\psi} &
    \jgmnt[\cEnv;\Theta,\formphi_2]{\psi}
  }{
    \jgmnt[\cEnv;\Theta]{\psi}
  }[(\ensuremath{\vee^e})]
  $ \\ \\ \hline
  \end{tabular}
  \caption{Natural deduction}
  \label{fig:deduction}
\end{figure}

Inference rules for quantifiers are rather straightforward,
with the only novelty being that we differtiate between atom and term
quantification, and restrict the quantified name to be \it{fresh} in the environment (it may not occur in any of the assumptions).

\begin{figure}[htbp]
  \centering
  \begin{tabularx}{\textwidth}{|C|}
  \hline \\ $
  \inference{
    \atomv \notin \fv[\cEnv;\Theta] &
    \jgmnt[\cEnv;\Theta]{\formphi}
  }{
    \jgmnt[\cEnv;\Theta]{\fForallAtom{\atomv}\formphi}
  }[(\ensuremath{{\fForallAtom{}}^i})]
  \qquad
  \inference{
    \jgmnt[\cEnv;\Theta]{\fForallAtom{\atomv}\formphi}
  }{
    \jgmnt[\cEnv;\Theta]{\formphi \{\atomv \mapsto \atomv'\}}
  }[(\ensuremath{{\fForallAtom{}}^e})]
  $ \\ \\ $
  \inference{
    \termv \notin \fv[\cEnv;\Theta] &
    \jgmnt[\cEnv;\Theta]{\formphi}
  }{
    \jgmnt[\cEnv;\Theta]{\fForallTerm{\termv}\formphi}
  }[(\ensuremath{{\fForallTerm{}}^i})]
  \qquad
  \inference{
    \jgmnt[\cEnv;\Theta]{\fForallTerm{\termv}\formphi}
  }{
    \jgmnt[\cEnv;\Theta]{\formphi \{\termv \mapsto \termv'\}}
  }[(\ensuremath{{\fForallTerm{}}^e})]
  $ \\ \\ $
  \inference{
    \jgmnt[\cEnv;\Theta]{\formphi \{\atomv \mapsto \atomv'\}}
    }{
    \jgmnt[\cEnv;\Theta]{\fExistsAtom{\atomv}\formphi}
  }[\textsc{ExistsAtomI}]
  \qquad
  \inference{
    \jgmnt[\cEnv_1;\Theta_1]{\fExistsAtom{\atomv}\formphi} \\
    \jgmnt[\cEnv_2;\Theta_2,\formphi \{\atomv \mapsto \atomv'\}]{\psi} \\
    \atomv' \notin \fv[\cEnv_1 \cup \cEnv_2;\Theta_2 \cup \Theta_2]
    }{
    \jgmnt[\cEnv_1 \cup \cEnv_2;\Theta_2 \cup \Theta_2]{\psi}
  }[\textsc{ExistsAtomE}]
  $ \\ \\ $
  \inference{
    \jgmnt[\cEnv;\Theta]{\formphi \{\termv \mapsto \termv'\}}
    }{
    \jgmnt[\cEnv;\Theta]{\fExistsTerm{\termv}\formphi}
  }[\textsc{ExistsTermI}]
  \qquad
  \inference{
    \jgmnt[\cEnv_1;\Theta_1]{\fExistsTerm{\termv}\formphi} \\
    \jgmnt[\cEnv_2;\Theta_2,\formphi \{\termv \mapsto \termv'\}]{\psi} \\
    \termv' \notin \fv[\cEnv_1 \cup \cEnv_2;\Theta_2 \cup \Theta_2]
    }{
    \jgmnt[\cEnv_1 \cup \cEnv_2;\Theta_2 \cup \Theta_2]{\psi}
  }[\textsc{ExistsTermE}]
  $ \\ \\ $
  \inference{
    \jgmnt[\cEnv;\Theta, (\fForallTerm{\termv'} \fCImp{\termv' \cshlt \termv} \formphi(\termv'))]{\formphi(\termv)}
    }{
    \jgmnt[\cEnv;\Theta]{\fForallTerm{\termv} \formphi(\termv)}
  }[\textsc{Induction}]
  $ \\ \\ \hline
  \end{tabularx}
  \caption{Quantifiers}
  \label{fig:quantifiers}
\end{figure}

\begin{figure}[htbp]
\centering
\begin{tabularx}{\textwidth}{|C|}
  \hline \\
$
  \inference{
    \cjgmnt[\cEnv]{\atomv \ceq \atomexp} &
    \jgmnt[\cEnv;\Theta]{\formphi}
    }{
    \jgmnt[\cEnv\{\atomv \mapsto \atomexp\};\Theta\{\atomv \mapsto \atomexp\}]{\formphi\{\atomv \mapsto \atomexp\}}
  }[\textsc{SubAtom}]
$ \\ \\ $
  \inference{
    \cjgmnt[\cEnv]{\termv \ceq \term} &
    \jgmnt[\cEnv;\Theta]{\formphi}
    }{
    \jgmnt[\cEnv\{\termv \mapsto \term\};\Theta\{\termv \mapsto \term\}]{\formphi\{\termv \mapsto \term\}}
  }[\textsc{SubTerm}]
$ \\ \\ $
  \inference{
    \jgmnt[\cEnv;\Theta]{\psi} &
    \jgmnt[\cEnv;\Theta]{\psi \equiv \formphi}
    }{
    \jgmnt[\cEnv;\Theta]{\formphi}
  }[\textsc{Equiv}]
$ \\ \\ \hline
\end{tabularx}
\caption{Flexibility rules}
\label{fig:flexibility}
\end{figure}

To make the framework more flexible we introduce a way for using equivalent formulas:
And a way to substitute atoms for atomic expression and variables for terms, if the solver can prove their equality:
Finally, we define induction over term structure,
and thanks to the constraints sublogic we can easily define the notion of
\it{smaller terms} needed for the inductive hypothesis:

\begin{figure}[htpb]
  \centering
  \begin{tabularx}{\textwidth}{|C|}
  \hline
  \\ $
  \inference{
  }{
    \jgmnt[]{\fForallAtom{\:\atomv,\:\atomv'} (\atomv \ceq \atomv') \vee (\atomv \cneq \atomv')}
  }[\textsc{AxiomCompare}]
  $ \\ \\ $
  \inference{
  }{
    \jgmnt[]{\fForallTerm{\termv} \:\fExistsAtom{\atomv} (\atomv \cfresh \termv)}
  }[\textsc{AxiomFresh}]
  $ \\ \\ $
  \inference{
  }{
    \jgmnt[]{\fForallTerm{\termv} (\fExistsAtom{\atomv}\: \termv = \atomv) \vee (\fExistsAtom{\atomv}\:\fExistsTerm{\termv'}\: \termv = \tbind{\atomv}{\termv'}) }
  }[\textsc{AxiomInversion}] $ \\
  $\vee \: (\fExistsTerm{\termv_1,\:\termv_2}\: \termv = \tbind{\atomv}{\termv'}) \vee ({symbol}\: \termv) \qquad\qquad$ \\
  \\
  \hline
  \end{tabularx}
  \caption{Axioms}
  \label{fig:axioms}
\end{figure}
The only axioms of our logic are strictly related to constraints:
\begin{enumerate}
\item We can deterministically compare any two atoms,
\item There always exists a fresh atom,
\item We can always deduce the structure of a term.
\end{enumerate}

The equivalence relation ($\formphi_1 \equiv \formphi_2$) is a bit complicated
due to subkinding, existence of formulas
with fixpoints, functions, applications,
and presence of an environment with variable mapping.
Nonetheless, it's simply that - \it{an equivalence relation} - and it
behaves as expected. We will only highlight the interesting parts.

\begin{figure}[htbp]
  \centering
\begin{tabularx}{\textwidth}{|rL|}
\hline & \\
$\tt{compute }\Sigma\tt{ }n\tt{ }P \;\:\leadsto$ &
$\tt{compute }\Sigma\tt{ }n\tt{ }\formphi$
\\
when & $\Sigma(P) = \formphi$
\\ & \\
$\tt{compute }\Sigma\tt{ }n\tt{ }{(\formphi \fAppAtom \atomexp )} \;\:\leadsto$ &
$\tt{compute }\Sigma\tt{ }(n' - 1)\tt{ }{\formphi'\subst{\atomv}{\atomexp}}$ \\
when & $\tt{compute }\Sigma\tt{ }n\tt{ }{\formphi} \;\leadsto^{*}\; (n',\fLamAtom{\atomv}\formphi')$
\\ & \\
$\tt{compute }\Sigma\tt{ }n\tt{ }{(\formphi \fAppTerm \term )}\;\:\leadsto$ &
$\tt{compute }\Sigma\tt{ }(n' - 1)\tt{ }\formphi'\subst{\termv}{\term}$ \\
when & $\tt{compute }\Sigma\tt{ }n\tt{ }{\formphi} \;\leadsto^{*}\; (n',\fLamTerm{\termv}\formphi')$
\\ & \\
$\tt{compute }\Sigma\tt{ }n\tt{ }{(\formphi \fAppTerm \term )}\;\:\leadsto$ &
$\tt{compute }\Sigma\subst{P}{\phi'}\tt{ }(n' - 1)\tt{ }{\formphi'\subst{\termv}{\term}}$\\
when & $\tt{compute }\Sigma\tt{ }n\tt{ }{\formphi} \;\leadsto^{*}\; (n',\fix{P}{\termv}{\kind}\formphi')$
\\ & \\
$\quad\tt{ compute }\Sigma\tt{ }n\tt{ }{(\formphi_1 \fApp \formphi_2 )}\;\:\leadsto$ &
$\tt{compute }\Sigma\tt{ }(n_2 - 1)\tt{ }{\psi_1\subst{\propv}{\psi_2}}$\\
when & $\tt{compute }\Sigma\tt{ }n\tt{ }{\formphi_1} \;\leadsto^{*}\; (n_1, \fLamForm{\propv}{\kind}{\psi_1})$\\
and & $\tt{compute }\Sigma\tt{ }n_1\tt{ }{\formphi_2} \;\leadsto^{*}\; (n_2, \psi_2)$
\\ & \\ \hline
\end{tabularx}
  \caption{Computing weak head normal form}
  \label{fig:compute}
\end{figure}
Equivalence checking procedure starts by computing weak head normal form (up to some \it{depth} denoted by $n$).
If we have a WHNF computed or if we've reached the limit of computation (when $ n \leqslant 0$) then we try to progress with equivelnce by recursing on the structure of formulas:
\\
$$
  \inference{
    \jgmnt[\Gamma; \Sigma]{\formphi_1 \equiv \formphi_2 } &
    \jgmnt[\Gamma; \Sigma]{\psi_1 \equiv \psi_2 }
    }{
    \jgmnt[\Gamma; \Sigma]{\formphi_1 \fImp \psi_1 \equiv \formphi_2 \fImp \psi_2 }
  }
  \quad
  \inference{
    \cjgmnt[\Gamma]{\term_1 \ceq \term_2} &
    \jgmnt[\Gamma; \Sigma]{\formphi_1 \equiv \formphi_2 }
    }{
    \jgmnt[\Gamma; \Sigma]{\formphi_1 \fAppTerm \term_1 \equiv \formphi_2 \fAppTerm \term_2 }
  }
  \quad
  \cdots
$$
\\
Note that we allow \it{different terms} in equivalent formulas as long as
constraints-enviroment $\cEnv$ ensures their equality is provable.
For functions, we simply substitute the arguments of both left and right side
to the same, fresh name.
\\
$$
  \inference{
    \termv \notin \fv[\Gamma; \Sigma] \\
    \jgmnt[\Gamma; \Sigma]{\formphi_1[\termv_1 \mapsto \termv] \equiv \formphi_2[\termv_2 \mapsto \termv] }
    }{
    \jgmnt[\Gamma; \Sigma]{\fLamTerm{\termv_1}\formphi_1 \equiv \fLamTerm{\termv_2}\formphi_2 }
  }
$$

$$
  \inference{
    \kind_1 \subkind \kind_2 \\
    \jgmnt[\Gamma; \Sigma]{\formphi_1[P_1 \mapsto P] \equiv \formphi_2[P_2 \mapsto P] }
    }{
    \jgmnt[\Gamma; \Sigma]{\fLamForm{P_1}{\kind_1}{\formphi_1} \equiv \fLamForm{P_2}{\kind_2}{\formphi_2}}
  }
$$

$$
  \inference{
    \kind_1 \subkind \kind_2 &
    P \notin \fv[\Gamma; \Sigma] & \termv \notin \fv[\Gamma; \Sigma] \\
    \jgmnt[\Gamma; \Sigma]{\formphi_1[P_1 \mapsto P, \termv_1 \mapsto \termv] \equiv \formphi_2[P_2 \mapsto P, \termv_2 \mapsto \termv] }
    }{
    \jgmnt[\Gamma; \Sigma]{\fix{P_1}{\termv_1}{\kind_1}\formphi_1 \equiv \fix{P_2}{\termv_2}{\kind_2}\formphi_2}
  }
$$
Quantifiers are handled the same way as function above --- as they all are a form of bind.
To handle formulas with constraints we introduce \it{constraint equivalence} relation,
which does nothing more than use the Solver to check that the constructors
of constraint are the same and that arguments are equal to each other in the Solver's sense,
analogusly as with terms above.
\\
$$
  \inference{
    \jgmnt[\Gamma]{\constr_1 \equiv \constr_2 } &
    \jgmnt[\Gamma; \Sigma]{\formphi_1 \equiv \formphi_2 }
  }{
    \jgmnt[\Gamma; \Sigma]{\fCAnd{\constr_1}\formphi_1 \equiv \fCAnd{\constr_2}\formphi_2 }
  }
\qquad
  \inference{
    \cjgmnt[\Gamma]{\atomv_1 \ceq \atomv_2 } & \cjgmnt[\Gamma]{\term_1 \ceq \term_2 }
  }{
    \jgmnt[\Gamma]{(\atomv_1 \cfresh \term_1) \equiv (\atomv_2 \cfresh \term_2) }
  }
\qquad
\cdots
$$
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \chapter{Model}

% Definition of a model of our logic is bit involved,
% due to presence of subkinding relation.
% We will proceed in two steps.
% First, for each kind $\kind$ we define its \emph{domain} $\kindDom{\kind}$.
% Then we will interpret each kind as a predicate on elements of its domain.
% We fix some Heyting algebra $\PropAlg$
% in which we will interpret propositions.
% Then kind domains are defined in the following way.
% \begin{eqnarray*}
% \kindDom{\kProp}                     & = & \PropAlg \\
% \kindDom{\kind_1 \karrow \kind_2}    & = & \kindDom{\kind_1} \rightarrow \kindDom{\kind_2} \\
% \kindDom{\kForallAtom{\atomv}\kind}  & = & \atomDom          \rightarrow \kindDom{\kind} \\
% \kindDom{\kForallTerm{\termv}\kind}  & = & \termDom          \rightarrow \kindDom{\kind} \\
% \kindDom{\kGuard{\constr}\kind}      & = & \kindDom{\kind}
% \end{eqnarray*}

% %%%%%%%%%%%%%%%%%%%%%%%
% And kind interpretation like this:
% \begin{eqnarray*}
% \termMdl{\kProp}{\tmEnv}                      & = & \{ \bot, \top \} \\
% \termMdl{\kind_1 \karrow \kind_2}{\tmEnv}     & = & \{f \mid \forall P \in \termMdl{\kind_1}{\tmEnv}.\: f(P) \in \termMdl{\kind_2}{\tmEnv} \} \\
% \termMdl{\kForallAtom{\atomv}\kind}{\tmEnv}   & = & \{f \mid \forall A \in \atomDom.\: f(A) \in \termMdl{\kind}{\tmEnv[\atomv \mapsto A]}\} \\
% \termMdl{\kForallTerm{\termv}\kind}{\tmEnv}   & = & \{f \mid \forall T \in \termDom.\: f(T) \in \termMdl{\kind}{\tmEnv[\termv \mapsto T]}\} \\
% \termMdl{\kGuard{\constr}\kind}{\tmEnv}       & = & \{x \mid \tmEnv \vDash \constr \implies x \in \termMdl{\kind}{\tmEnv} \}
% \end{eqnarray*}



% And finally the kind derivation model:
% \begin{eqnarray*}
% \interp{\inference{ }{\types{\top}{\kProp}}} & = & \top \\
% \interp{\inference{ }{\types{ \propv}{\Gamma( \propv)}}} & = & \tmEnv(\propv) \\
%     \interp{\inference{}{\types{\constr}{\kProp}}} & = & \texttt{if } \tmEnv \vDash \constr \texttt{ then } \top \texttt{ else } \bot
% \end{eqnarray*}

% \begin{eqnarray*}
%     \interp{
%         \inference{D_1 : \types{\formphi_1 }{\kProp} \\ D_2 : \types{\formphi_2 }{\kProp}
%     }{
%         \types{\formphi_1 \wedge \formphi_2}{\kProp}}
%     } & = & \interp{D_1} \wedge_\PropAlg \interp{D_2} \\
%     \interp{
%         \inference{D_1 : \types{\formphi_1 }{\kProp}  \\ D_2 : \types{\formphi_2 }{\kProp}
%     }{
%         \types{\formphi_1 \vee \formphi_2}{\kProp}}
%     } & = & \interp{D_1} \vee_\PropAlg \interp{D_2} \\
%     \interp{
%         \inference{D_1 : \types{\formphi_1 }{\kProp}  \\ D_2 : \types{\formphi_2 }{\kProp}
%     }{
%         \types{\formphi_1 \Rightarrow \formphi_2}{\kProp}}
%     } & = & \interp{D_1} \Rightarrow_\PropAlg \interp{D_2}
% \end{eqnarray*}

% \begin{eqnarray*}
%     \interp{
%         \inference{D : \types{\formphi}{\kProp}
%     }{
%         \types{\fForallTerm{\termv}\formphi}{\kProp}}
%     } & = & \underset{T \in Term}{\bigwedge} {\interp[{\tmEnv [\termv \mapsto T]}]{D}}  \\
%     \interp{
%         \inference{D : \types{\formphi}{\kProp}
%     }{
%         \types{\fForallAtom{\atomv}\formphi}{\kProp}}
%     } & = & \underset{A \in Atom}{\bigwedge} {\interp[{\tmEnv [\atomv \mapsto A]}]{D}} \\
%     \interp{
%         \inference{D : \types{\formphi}{\kProp}
%     }{
%         \types{\fExistsTerm{\termv} \formphi}{\kProp}}
%     } & = & \underset{T \in Term}{\bigvee}\interp[{\tmEnv [\termv \mapsto T]}]{D} \\
%     \interp{
%         \inference{D : \types{\formphi}{\kProp}
%     }{
%         \types{\fExistsAtom{\atomv} \formphi}{\kProp}}
%     } & = & \underset{A \in Atom}{\bigvee} \interp[{\tmEnv [\atomv \mapsto A]}]{D}
% \end{eqnarray*}

% \begin{eqnarray*}
%    \interp{
%         \inference{D : \types[\Gamma, c]{\formphi}{\kProp}
%     }{
%         \types{[c] \wedge \formphi}{\kProp}}
%     } & = &  \texttt{if } \tmEnv \vDash c \texttt{ then } \interp{D} \texttt{ else } \bot
%     \\
%     \interp{
%         \inference{D : \types[\Gamma, c]{\formphi}{\kProp}
%     }{
%         \types{[c] \Rightarrow \formphi}{\kProp}}
%     } & = &  \texttt{if } \tmEnv \vDash c \texttt{ then } \interp{D} \texttt{ else } \top
% \end{eqnarray*}

% \begin{eqnarray*}
%     \interp{\inference{D : \types{\formphi}{\kind_2}}{\types{\lam[\propv]\formphi}{\kind_1\karr\kind_2}}} & = &
%     \lambda\;(Q : \interp{\kind_1}).\;\interp[{\tmEnv[\propv\mapsto Q]}]{D}
%     \\
%     \interp{\inference{D: \types{\formphi}{\kind}}{\types{\lam[\atomv]\formphi}{\kForallAtom{\atomv}\kind}}} & = &
%     \lambda\;(A : Atom).\;\interp[{\tmEnv[\atomv\mapsto A]}]{D}
%     \\
%     \interp{\inference{D: \types{\formphi}{\kind}}{\types{\lam[\termv]\formphi}{\kForallTerm{\termv}\kind}}} & = &
%     \lambda\;(T : Term).\;\interp[{\tmEnv[\termv\mapsto T]}]{D}
% \end{eqnarray*}

% \begin{eqnarray*}
%     \interp{\inference{D_1: \types{\formphi_1}{\kind'\karr\kind} \\ D_2: \types{\formphi_2}{\kind'}}{\types{\formphi_1\;\formphi_2}{\kind}}} & = &
%     \interp{D_1}\; \interp{D_2}
%     \\
%     \interp{\inference{D: \types{\formphi}{\kForallAtom{\atomv}\kind}}{\types{\formphi(\atomexp)}{\kind\{\atomv \mapsto \atomexp\}}}} & = &
%     \interp{D}\;\interp{\atomexp}
%     \\
%     \interp{\inference{D: \types{\formphi}{\kForallTerm{\termv}\kind}}{\types{\formphi(\term)}{\kind\{\termv \mapsto \term\}}}} & = &
%     \interp{D}\;\interp{\termv}
% \end{eqnarray*}

% %  lim w sensie tw kleenego o fixpoincie
% \begin{eqnarray*}
%     \interp{\inference{
%             D : \types[{\Gamma, X : {\all[z]{[z < \termv']}}\;\kind\subst{z}{\termv'}}]\formphi\kind
%         }{
%             \types{\fix{X}{\termv'}\formphi}{\all[\termv']\kind}
%         }} & = & \lim_{n \rightarrow \infty} f_n
%     \\
%     & & \texttt{ where } f_0(t) = \bot \\
%     & & \texttt{ and } f_{n+1}(t) = \interp[{\tmEnv[X\mapsto f_n, \termv' \mapsto t]}]{D} \\
%     \interp{\inference{
%             D : \types[\Gamma, c]\formphi\kind
%         }{
%             \types{\formphi}{[c]\kind}
%         }} & = & \texttt{if } \tmEnv \vDash c \texttt{ then } \interp{D} \texttt{ else } \text{''}\bot\text{''}
%     \\
%     \interp{\inference{
%             D : \types\formphi\kind \\
%             \rel[\Gamma] \kind \leq \kind'
%         }{
%             \types{\formphi}{\kind'}
%         }} & = &  \interp{D}
% \end{eqnarray*}

% \section{Fundamental Theorem}
% For any formula $\formphi$, any kind $\kind$, and any environment $\Gamma$, for any kind derivation $D : \types\formphi\kind$ under any interpretation $\tmEnv \in \interp[]{\Gamma}$, we have that
% $$
%     \interp{D} \in \interp{\kind}
% $$
% In other words, each kind derivation $D$ has a semantic witness that inhabits the semantic interpretation of $\kind$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Implementation}
All the concepts discussed in previous chapters have been implementation in OCaml.
Atoms and variables are represented internally by integers (yet remain disjoint sets)
--- and their string \it{names} are kept within the environment and binders
(quantifiers and functions).
Terms, constraints, kinds, and formulas are defined in \tt{Types} module,
mirroring their previusly described grammars.
The only difference is that we allow conjunction and disjunction to be used with
more than two arguments, with the added feature of arguments being labeled by names.
This naming approach lets the user to easily select desired branches while composing proofs
or to give meaningful names within the definition of properties.

The \it{Solver} ihabits its own dedicated \tt{Solver} module along with \tt{SolverEnv}
responsible for implementing the specialized environment $\icEnv$ handling the \hyperref[sec:solverenv]{irreducible assumptions}.
Analogously, the \tt{KindChecker} and \tt{KindCheckerEnv} modules serve similar roles.

The proof theory described in previous chapter is distributed over modules
\tt{Proof}, \tt{ProofEnv}, \tt{ProofEquiv} and is a direct implementation of the proof-theoretic rules.
TODO: keep what's interesting, lose what's not
\begin{lstlisting}[mathescape, language=OCaml, escapebegin=\color{codegreen}]
(* Module: SolverEnv *)
type SolverEnv.t

val add_fresh : atom -> var -> SolverEnv.t -> SolverEnv.t

...

val occurs_check : SolverEnv.t -> var -> shape -> bool

(* Module: Proof *)

(* ----------- *)
(*  $\Gamma$; f $\vdash$ f   *)
val assumption : 'a env -> formula -> proof

(*    $\Gamma$; $\Theta$, f1 $\vdash$ f2   *)
(* ------------------- *)
(*  $\Gamma$; $\Theta$ $\vdash$ f1 $\implies$ f2  *)
val imp_i : formula -> proof -> proof

(*  $\Gamma$1; $\Theta$1 $\vdash$ f1 $\implies$ f2    $\Gamma$2; $\Theta$2 $\vdash$ f2  *)
(* ------------------------------------- *)
(*        $\Gamma$1 $\cup$ $\Gamma$2; $\Theta$1 $\cup$ $\Theta$2 $\vdash$ f2         *)
val imp_e : proof -> proof -> proof

(*  $\Gamma$; $\Theta$ $\vdash$ $\bot$  *)
(* ----------- *)
(*  $\Gamma$; $\Theta$ $\vdash$ f  *)
val bot_e : formula -> proof -> proof

(*   $\Gamma$ $\vDash$ c    *)
(* ---------- *)
(*  $\Gamma$; $\Theta$ $\vdash$ c  *)
val constr_i : proof_env -> constr -> proof
\end{lstlisting}
Note that the \tt{Proof} modules provide methods for constructing forward proofs, i.e., those in which more complex conclusions are built from simpler, already proven facts.
Unfortunately, this \it{bottom-up} way is not the most convenient method for conducting proofs in intuitionistic logic --- it is significantly easier to construct proofs in \it{top-down}, backwards fashion through simplifying the goal to be proven until we reach trivial matters.
As such proofs are incomplete by nature, they must have \it{holes},
and live within some \it{proof context}, as defined in modules \tt{IncProof}.

TODO: write it better:\\
Naturally that makes the implementation much more complex, so the appropriate level of confidence in proven propositions will be achieved through other means:
we delegate the responsibility for the correctness of the proofs to the \tt{Proof} module, and the \tt{IncProof} module serves as a kind of facade for it.

\section{Proof assistant}
To facilitate user interaction with this framework, we provide a practical \it{proof assistant}.
While simple, it is also powerful and easy to use.
The interface defined in modules \tt{Prover}, \tt{ProverInternals}, and \tt{Tactics} provides multiple \it{tactics}
(functions that manipulate \it{prover state}) and ways to combine them.


\begin{lstlisting}[mathescape, language=OCaml]
type prover_state = S_Unfinished of (goal * proof_context)
                  | S_Finished of proof

type tactic = prover_state $\rightarrow$ prover_state

val proof : goal_env $\rightarrow$ formula $\rightarrow$ prover_state

val qed : prover_state $\rightarrow$ proof

val (|>) : prover_state $\rightarrow$ tactic $\rightarrow$ prover_state

val (%>) : tactic $\rightarrow$ tactic $\rightarrow$ tactic

val repeat : tactic $\rightarrow$ tactic

val try_tactic : tactic $\rightarrow$ tactic
\end{lstlisting}
\newcommand{\hole}{\ensuremath{\bullet}}
\begin{eqnarray*}
  \text{\lstinline[columns=fixed]{proof}}\;(\Gamma,\Theta,\Sigma)\;\formphi &  \leadsto & \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind\formphi}
  \end{eqnarray*}
We begin description of the Prover interface with \it{empty} proof constructor,
using $\hole\ofkind\formphi$ to describe incomplete proofs,
called \it{holes} or \it{goals}.
TODO: put it in a figure I guess?
\begin{eqnarray*}
  \text{\lstinline[columns=fixed]{intro}} & & \\
    \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{\fCImp{\constr}{\formphi}}} & \leadsto & \jgmnt[\Gamma, \constr; \Theta; \Sigma]{\hole\ofkind\formphi} \\
  & & \\
  \text{\lstinline[columns=fixed]{intro' x}} & & \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{\psi\fImp\formphi}} & \leadsto & \jgmnt[\Gamma; \Theta, \tt{x} \ofkind\psi ; \Sigma]{\hole\ofkind\formphi} \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{\fForallAtom{\atomv}{\formphi}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma, \tt{x} \ofkind\atomv]{\hole\ofkind\formphi} \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{\fForallTerm{\termv}{\formphi}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma, \tt{x} \ofkind\termv]{\hole\ofkind\formphi} \\
  & & \\
  \text{\lstinline[columns=fixed]{apply} } (\psi \fImp \formphi)& & \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{{\formphi}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind\psi} \\
  &   \text{and} & \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind\psi \fImp \formphi} \\
  & & \\
  \text{\lstinline[columns=fixed]{apply_thm} }  \mathcal{T} & & \\
    \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{{\formphi}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind\psi} \\
   & \text{where} & \mathcal{T} \;\text{is a proof of }\; {\psi \fImp \formphi } \\
  & & \\
  \text{\lstinline[columns=fixed]{apply_assm H}} & & \\
    \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{{\formphi}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind\psi} \\
   & \text{when} & (\tt{H} \ofkind {\psi\fImp\formphi }) \in \Theta \\
  & & \\
  \text{\lstinline[columns=fixed]{apply_assm_spec H [e; a]}} & & \\
    \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{{\formphi(\tt{e}, \tt{a})}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind\psi(\tt{e}, \tt{a})} \\
   & \text{when} & (\tt{H} \ofkind {\kForallTerm{X}\kForallAtom{a} \psi(X, a)\fImp\formphi(X, a) }) \in \Theta
  \end{eqnarray*}
Now, some typical tactics: introduction of names and assumptions and applying of
propositions and theorems.
Note that propositions can be applied not only on the goal, but also on other
assumptions via \tt{apply\_in\_assumption} tactic.
One can also add introduce assumptions to the proof context from theorems via \tt{add\_assumption\_thm}
(specialized if needed via \tt{add\_assumption\_thm\_spec}) --
or simply add any assumption to the current context together with a new goal (of proving that assumption)
via \tt{add\_assumption}.
\begin{eqnarray*}  \text{\lstinline[columns=fixed]{apply_assm H}} & & \\
    \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{{\formphi}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma]{\formphi} \\
   & \text{when} & (\tt{H} \ofkind {\formphi }) \in \Theta \\
  & & \\
  \text{\lstinline[columns=fixed]{solve} }& & \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{{\constr}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma]{\constr} \\
   & \text{when} & \cjgmnt[\Gamma]{\constr}\\
  & & \\
  \text{\lstinline[columns=fixed]{discriminate} }& & \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{{\formphi}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma]{\formphi} \\
   & \text{when} & \cjgmnt[\Gamma]{\bot}
  \end{eqnarray*}
Above tactics finish the proofs, either by finding the goal in assumptions
(which can be made automatically via tactical\tt{assumption}),
or by running Solver on constraint-assumption and the goal.
Technical detail is that all formulas in $\Theta$ that are actually constraints
will also be included in calls to Solver.
\begin{eqnarray*}
  \text{\lstinline[columns=fixed]{exists e} }& & \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{\fExistsAtom{\atomv}{\formphi}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{\formphi\subst{\atomv}{\tt{e}}}} \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{\fExistsTerm{\termv}{\formphi}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{\formphi\subst{\termv}{\tt{e}}}} \\
  & & \\
  \text{\lstinline[columns=fixed]{destr_goal} }& & \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{\fCAnd{\constr}\formphi}} & \leadsto & \jgmnt[\Gamma; \Theta;\Sigma]{\hole\ofkind{\constr}} \\
  & \text{and} & \jgmnt[\Gamma, \constr; \Theta;\Sigma]{\hole\ofkind{\formphi}} \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{\formphi_1 \wedge \formphi_2}} & \leadsto & \jgmnt[\Gamma; \Theta;\Sigma]{\hole\ofkind{\formphi_1}} \\
  & \text{and} & \jgmnt[\Gamma; \Theta;\Sigma]{\hole\ofkind{\formphi_2}} \\
  & & \\
  \text{\lstinline[columns=fixed]{left} } & \equiv &  \text{\lstinline[columns=fixed]{case l} } \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{(\tt{l:}\:\formphi_1) \vee (\tt{r:}\:\formphi_2)}} & \leadsto & \jgmnt[\Gamma; \Theta;\Sigma]{\hole\ofkind{\formphi_1}} \\
  \text{\lstinline[columns=fixed]{right} } & \equiv &  \text{\lstinline[columns=fixed]{case r} } \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{(\tt{l:}\:\formphi_1) \vee (\tt{r:}\:\formphi_2)}} & \leadsto & \jgmnt[\Gamma; \Theta;\Sigma]{\hole\ofkind{\formphi_2}} \\
  \end{eqnarray*}
Tactics above reduce the current goal.
\begin{eqnarray*}
  \text{\lstinline[columns=fixed]{destr_assm H} }& & \\
  \jgmnt[\Gamma; \Theta \cup \{\tt{H}\ofkind \fCAnd{\constr}{\formphi} \}; \Sigma]{\hole\ofkind{\formphi}} & \leadsto & \jgmnt[{\Gamma \cup \{\constr\}}; \Theta \cup {\{ \tt{H} \ofkind \formphi\}}; \Sigma]{\hole\ofkind{\formphi}} \\
  \jgmnt[\Gamma; \Theta \cup \{\tt{H}\ofkind \formphi_1 \wedge \formphi_2 \}; \Sigma]{\hole\ofkind{\formphi}} & \leadsto & \jgmnt[{\Gamma; \Theta \cup {\{ \tt{H\_1}\ofkind \formphi_1, \tt{H\_2}\ofkind \formphi_2\}}; \Sigma}]{\hole\ofkind{\formphi}} \\
  \jgmnt[\Gamma; \Theta \cup \{\tt{H}\ofkind \formphi_1 \vee \formphi_2 \}; \Sigma]{\hole\ofkind{\formphi}} & \leadsto & \jgmnt[\Gamma; \Theta  \cup \{\tt{H}\ofkind \formphi_1\}; \Sigma]{\hole\ofkind{\formphi}} \\
  & \text{and} & \jgmnt[\Gamma; \Theta  \cup \{\tt{H}\ofkind \formphi_2\}; \Sigma]{\hole\ofkind{\formphi}} \\
  \text{\lstinline[columns=fixed]{destr_assm' H x} }& &
  \\
  \jgmnt[\Gamma; \Theta \cup \{\tt{H}\ofkind\fExistsAtom{\atomv}{\formphi} \}; \Sigma]{\hole\ofkind{\formphi}} & \leadsto & \jgmnt[\Gamma ; \Theta \cup {\{\tt{H}\ofkind\formphi\subst{\atomv}{\tt{x}}\}}; \Sigma\cup {\{\tt{x} \ofkind {A}\}}]{\hole\ofkind{\formphi}} \\
  \jgmnt[\Gamma; \Theta \cup \{\tt{H}\ofkind\fExistsTerm{\termv}{\formphi} \}; \Sigma]{\hole\ofkind{\formphi}} & \leadsto & \jgmnt[\Gamma ; \Theta \cup {\{\tt{H}\ofkind\formphi\subst{\termv}{\tt{x}}\}}; \Sigma\cup {\{\tt{x} \ofkind {T}\}}]{\hole\ofkind{\formphi}} \\
   & \text{when} & \tt{x} \notin \fv[\Gamma; \Theta; \Sigma]
  \end{eqnarray*}
Tactics above reduce formulas in assumptions.
Note that the user provides \tt{destr\_assm'} with a \it{name} that will be bound
with existential variable, but the binding is done \it{behind the scenes} and
actually any string can be given and an unique internal identifier is generated.
\begin{eqnarray*}
  \text{\lstinline[columns=fixed]{ex_falso} } & & \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{{\formphi}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind\bot} \\
  & & \\
  \text{\lstinline[columns=fixed]{generalize x} }& & \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{{\formphi}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma']{\hole\ofkind{\kForallTerm{\tt{x}}{\formphi}}} \\
  & \text{when} & \Sigma = \Sigma' \cup \{\tt{x}\} \text{ and } \tt{x} \notin \fv[\Gamma] \\
  & & \\
  \text{\lstinline[columns=fixed]{by_induction x IH} } & & \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{(\fForallTerm{\termv}\formphi(\termv))}} & \leadsto & \jgmnt[\Gamma; \Theta \cup \{\tt{IH} \ofkind \psi \};\Sigma\cup \{\tt{x} \ofkind {T}\}]{\hole\ofkind{\formphi(\termv)}} \\
   & \text{where} & {\psi := \fForallTerm{\tt{x}}\fCImp{\tt{x} \cshlt \termv}{\formphi(\tt{x})}}
  \end{eqnarray*}
Finally we can prove goals through generalization, induction on terms, and through reduction to absurd.
\begin{eqnarray*}
  \text{\lstinline[columns=fixed]{compare_atoms a b} }& & \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{{\formphi}}} & \leadsto & \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{(\tt{a} \ceq \tt{b} \vee \tt{a}\cneq \tt{b})\fImp{\formphi}}} \\
  & & \\
  \text{\lstinline[columns=fixed]{get_fresh_atom a e} }& & \\
  \jgmnt[\Gamma; \Theta; \Sigma]{\hole\ofkind{{\formphi}}} & \leadsto & \jgmnt[\Gamma \cup {\{\tt{a} \cfresh \tt{e}\}}; \Theta; \Sigma\cup {\{\tt{a} \ofkind {A}\}}]{\hole\ofkind{\formphi}} \\
   & \text{where} & \tt{a} \notin \fv[\Gamma; \Theta; \Sigma] \\
\end{eqnarray*}
We also provide shorthand formuals for using the axioms of our logic, described
in previous chapter.
Again argument \tt{a} to \tt{get\_fresh\_atom} is given by name and is bound by
a fresh internal identifier automatically.

Additional we provide the user with some auxiliary tactics:
\begin{itemize}
\item \tt{subst} --- substitutes atoms for atom expreesions
  and variables for terms in goal and environment
  --- as long as Solver proves their equality,
\item \tt{compute} --- computes WHNF of the current goal,
\item \tt{try} --- applies a tactic and returns unchanged state if the tactic fails
\item \tt{repeat} --- applies given tactic (until failure),
\item \tt{trivial} ---  tries applying some simple tactics
\end{itemize}
Finally, the function \texttt{qed} accepts a prover state and finalizes it.
If the proof state is indeed finished, the function transforms it into a forward proof.
This transformation guarantees correctness through the utilization of straightforward rules embedded within the \tt{proof} smart constructors.

Naturally, we also provide a pretty-printer, created using the \texttt{EasyFormat} library,
along with a parser developed using the \texttt{Angstrom} parser combinator library,
designed to handle terms, constraints, kinds, and formulas.
See how predicates such as ${Nat}$ and ${PlusEq}$ can be expressed using
programmer-friendly syntax:
\begin{lstlisting}[mathescape, language=OCaml, escapebegin=\color{codepurple}]
(* define symbols used in arithmetical theorems *)
let arith_symbols = symbols ["0"; "S"]

let nat = (* Nat n *)
 "fix Nat(n) : * =
    zero: (n = 0)
    $\vee$
    succ: ($\exists$ m :term. [n = S m] $\wedge$ Nat m)"

let plus_eq = (* PlusEq n m k *)
  "fix PlusEq(n) : $\forall$ m k : term. * = fun m k : term $\rightarrow$
     zero: ([n = 0] $\wedge$ [m = k])
     $\vee$
     succ: ($\exists$ n' k' :term. [n = S n'] $\wedge$ [k = S k'] $\wedge$ PlusEq n' m k')"
\end{lstlisting}
And a short proof that 1 is a natural number:
\begin{lstlisting}[mathescape, language=OCaml, escapebegin=\color{codegreen}]
let nat_1_thm = arith_thm "Nat {S 0}"

let nat_1 =
  proof' nat_1_thm (* goal: Nat {S 0} *)
  |> case "succ"   (* goal: $\exists$ m :term. [S 0 = S m] $\wedge$ Nat m *)
  |> exists "0"    (* goal: [S 0 = S 0] $\wedge$ Nat 0 *)
  |> solve         (* goal: Nat 0 *)
  |> case "zero"   (* goal: 0 = 0 *)
  |> solve         (* finished *)
  |> qed
\end{lstlisting}
Another example theorem could be the symmetry of addition:
\begin{lstlisting}[mathescape, language=OCaml, escapebegin=\color{codepurple}]
let plus_symm_thm = arith_thm
  "$\forall$ x y z :term. (IsNum x) $\implies$ (IsNum y) $\implies$
    (PlusEq x y z) $\implies$ (PlusEq y x z)"
\end{lstlisting}
The proof of which is included in the \tt{examples} subdirectory of the project,
together with the case study from the next chapter.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Case study: Progress and Preservation of STLC}

The ultimate goal of our work is to create a logic for dealing with variable binding,
and there's no better way to put it to work than to prove some things about lambda calculus.

We will take a look at simply typed lambda calculus and examine proofs of
its two major properties of \it{type soundness}: \it{progress} and \it{preservation}.
But before we delve into the proofs, let's first establish the needed relations:
\begin{lstlisting}[mathescape,language=OCaml, escapebegin=\color{codepurple}]
(* define symbols used in lambda calculus theorems *)
let lambda_symbols = ["lam"; "app"; "base"; "arrow"; "nil"; "cons"]

let term_predicate = (* Term e *)
  "fix Term(e): * =
     var: ($\exists$ a :atom. [e = a])
     $\vee$
     lam: ($\exists$ a :atom.$\exists$ e' :term. [e = lam (a.e')] $\wedge$ (Term e'))
     $\vee$
     app: ($\exists$ e1 e2 :term. [e = app e1 e2] $\wedge$ (Term e1) $\wedge$ (Term e2))"

let type_predicate = (* Type t *)
  "fix Type(t): * =
     base: (t = base)
     $\vee$
     arrow: ($\exists$ t1 t2 :term. [t $\ceq$ arrow t1 t2] $\wedge$ (Type t1) $\wedge$ (Type t2))"

let inenv_relation = (* InEnv env a t *)
  "fix InEnv(env): $\forall$ a :atom. $\forall$ t :term. * = fun (a :atom) (t :term) $\rightarrow$
     current: ($\exists$ env': term. [env = cons a t env'])
     $\vee$
     next: ($\exists$ b :atom. $\exists$ s env': term.
             [env = cons b s env'] $\wedge$ [a $\cneq$ b] $\wedge$ (InEnv env' a t))"

let typing_relation = (* Typing e env t *)
  "fix Typing(e): $\forall$ env t :term. * = fun env t :term $\rightarrow$
     var: ($\exists$ a :atom. [e = a] $\wedge$ (InEnv env a t))
     $\vee$
     lam: ($\exists$ a :atom.$\exists$ e' t1 t2 :term.
            [e = lam (a.e')] $\wedge$ [t = arrow t1 t2]
              $\wedge$ (Type t1) $\wedge$ (Typing e' {cons a t1 env} t2))
     $\vee$
     app: ($\exists$ e1 e2 t2 :term.
            [e = app e1 e2]
              $\wedge$ (Typing e1 env {arrow t2 t}) $\wedge$ (Typing e2 env t2))"
\end{lstlisting}
To state the theorem of \it{progress}, we will naturally need the predicate
that a term is \it{progressive}:
\begin{lstlisting}[mathescape,language=OCaml, escapebegin=\color{codepurple}]
let value_predicate = (* Value v *)
  "fun e :term $\rightarrow$
     var: ($\exists$ a :atom. [e = a])
     $\vee$
     lam: ($\exists$ a :atom. $\exists$ e' : term. [e = lam (a.e')] $\wedge$ (Term e'))"

 let sub_relation = (* Sub e a v e' *)
   "fix Sub(e): $\forall$ a :atom. $\forall$ v e':term.* = fun (a :atom) (v e' :term) $\rightarrow$
      var_same: ([e = a] $\wedge$ [e' = v])
      $\vee$
      var_diff: ($\exists$ b :atom. [e = b] $\wedge$ [e' = b] $\wedge$ [a $\cneq$ b])
      $\vee$
      lam: ($\exists$ b :atom. $\exists$ e_b e_b' :term.
             [e = lam (b.e_b)] $\wedge$ [e' = lam (b.e_b')] $\wedge$
             [b # v] $\wedge$ [a $\cneq$ b] $\wedge$ (Sub e_b a v e_b') )
      $\vee$
      app: ($\exists$ e1 e2 e1' e2' :term.
             [e = app e1 e2] $\wedge$ [e' = app e1' e2']
               $\wedge$ (Sub e1 a v e1') $\wedge$ (Sub e2 a v e2') )"
     (* TODO: describe why [lam] case is so cool *)

let env_inclusion_relation = (* EnvInclusion e1 *)
  "fun env1 env2 : term $\rightarrow$
     $\forall$ a : atom. $\forall$ t : term. (InEnv env1 a t) $\implies$ (InEnv env2 a t)"

let steps_relation = (* Steps e e' *)
  "fix Steps(e): $\forall$ e' :term.* = fun e' :term $\rightarrow$
     app_l: ($\exists$ e1 e1' e2 :term. [e = app e1 e2]
              $\wedge$ [e' = app e1' e2] $\wedge$ (Steps e1 e1') )
     $\vee$
     app_r: ($\exists$ v e2 e2' :term. [e = app v e2]
              $\wedge$ [e' = app v e2'] $\wedge$ (Value v) $\wedge$ (Steps e2 e2') )
     $\vee$
     app: ($\exists$ a :atom.$\exists$ e_a v :term. [e = app (lam (a.e_a)) v]
            $\wedge$ (Value v) $\wedge$ (Sub e_a a v e') )"

let progressive_predicate = (* Progressive e *)
  "fun e:term $\rightarrow$
     value: (Value e)
     $\vee$
     steps: ($\exists$ e' :term. Steps e e')"

(* lambda_thm parses the theorem in an env that includes lambda_symbols and all lambda predicates and relations *)
let progress_thm = lambda_thm
  "$\forall$ e t :term. (Typing e nil t) $\implies$ (Progressive e)"
\end{lstlisting}
We will also require a lemma about \it{canonical forms},
which states that all values in the empty environment
are of \it{arrow} type and can be \it{inversed} into an abstraction term
(since we did not consider any true base types like \tt{Bool} or \tt{Int}).
\begin{lstlisting}[mathescape,language=OCaml, escapebegin=\color{codepurple}]
let canonical_form_thm = lambda_thm
  "$\forall$ v :term. (Value v) $\implies$
   $\forall$ t :term. (Typing v nil t) $\implies$
     ($\exists$ a :atom. $\exists$ e :term. [v = lam (a.e)] $\wedge$ (Term e))"
\end{lstlisting}
As well as some boilerplate lemmas:
\begin{lstlisting}[mathescape,language=OCaml, escapebegin=\color{codepurple}]
let empty_contradiction_thm = lambda_thm
  "$\forall$ a :atom. $\forall$ t :term. (InEnv nil a t) $\implies$ false"

let typing_terms_thm = lambda_thm
  "$\forall$ e env t : term. (Typing e env t) $\implies$ (Term e)"

let subst_exists_thm = lambda_thm
  "$\forall$ a :atom.
   $\forall$ v :term. (Value v) $\implies$
   $\forall$ e :term. (Term e) $\implies$
     $\exists$ e' :term. (Sub e a v e')"
\end{lstlisting}
Lets begin with the proof of \it{canonical forms}:
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
let canonical_form =
  proof' canonical_form_thm
  |> intros ["v"; "t"; "Hv"; "Ht"]
(* Proof state:
[ ]
[ Ht : Typing v nil t ;
  Hv : Value v
]
$\vdash$ $\exists$ a :atom. $\exists$ e :term. [v = lam (a.e)] $\wedge$ Term e
*)
\end{lstlisting}
The proof will follow from case analysis of \tt{Typing} relation, so let's \it{destruct} assumption \tt{Ht}
and consider the first case, where \tt{v} is some variable \tt{a}.
This case is impossible in empty environment, so we named the assumption \tt{contra}
and show it through the tactic \tt{ex\_falso}.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
  |> destruct_assm "Ht"
  |> intros' ["contra"; "a"; ""]
     %> ex_falso
(* Proof state:
[ v = a ]
[ Hv : Value v ;
  contra : InEnv nil a t
]
$\vdash$ $\bot$
*)
     %> apply_thm_spec empty_contradiction ["a"; "t"]
        (* InEnv nil a t $\implies$ $\bot$ *)
     %> apply_assm "contra"
\end{lstlisting}
Next case is the only sensible one: that \tt{v} is some \tt{lam (a.e)} of type \tt{arrow t1 t2}.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
  |> intros' ["Hlam"; "a"; "e"; "t1"; "t2"; ""; ""; ""]
     %> exists' ["a"; "e"]
     %> solve
(* Proof state:
[ v = lam (a.e) ; t = arrow t1 t2]
[ Hlam : Type t1 $\wedge$ Typing e {cons a t1 nil} t2 ;
  ...
]
$\vdash$ Term e
*)
\end{lstlisting}
Now, obviously every term that \it{types} is indeed a proper \it{term},
so we simply use the \tt{typing\_terms} lemma and we're done here.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
     %> apply_thm_spec typing_terms ["e"; "cons a t1 nil"; "t2"]
        (* Typing e {cons a t1 nil} t2 $\implies$ Term e *)
     %> assumption
\end{lstlisting}
Final case is that \tt{e} is an application, but then it can't be a value,
so we analyse the \tt{Hv} assumption, arriving at contradiction in either case:
\begin{lstlisting}[mathescape, language=OCaml]
  |> intros' ["contra"; "e1"; "e2"; "t2"; ""]
     %> ex_falso
     %> destruct_assm "Hv"
(* Proof state:
[ v = app e1 e2 ]
[ contra : Typing e1 nil {arrow t2 t} $\wedge$ Typing e2 nil t2 ]
$\vdash$ ($\exists$ a : atom. v = a) $\implies$ $\bot$
*)
     %> intros' ["contra_var"; "a"]
     %> discriminate
(* Proof state:
[ v = app e1 e2 ]
[ contra : Typing e1 nil {arrow t2 t} $\wedge$ Typing e2 nil t2 ]
$\vdash$ ($\exists$ a : atom. $\exists$ e' : term. v = lam (a.e)) $\implies$ $\bot$
*)
     %> intros' ["contra_lam"; "a"; "e"; ""] %> discriminate
     %> discriminate
  |> qed
\end{lstlisting}
Now we can proceed with the proof of \it{progress}, a simple induction over $Typing$ derivation:
\begin{lstlisting}[mathescape, language=OCaml]
let progress =
  proof' progress_thm
  |> by_induction "e0" "IH" %> intro
(* Proof state:
[ ]
[ IH : $\forall$ e0 : term. [e0 $\cshlt$ e] $\implies$ $\forall$ t'1 : term.
        (Typing e0 nil t'1) $\implies$ Progressive e0 ]
$\vdash$ (Typing e nil t) $\implies$ Progressive e
*)
\end{lstlisting}
To analyze all the possible branches of the \tt{Typing} predicate,
we simply use \tt{{intro'}} tactic to destruct the assumption into multiple branches.
\begin{lstlisting}[language=OCaml]
  |> intro'
\end{lstlisting}
First one is that \tt{e} is a variable - which again contradicts with empty enviroment:
\begin{lstlisting}[language=OCaml, mathescape]
  |> intros' ["contra"; "a"; ""]
     %> ex_falso
(* Proof state:
[ e = a ]
[
  contra : InEnv nil a t ;
  ...
]
$\vdash$ $\bot$
*)
     %> apply_thm_spec empty_contradiction ["a"; "t"]
     %> assumption
\end{lstlisting}
Next, \tt{e} is a lambda abstraction - so a value.
\begin{lstlisting}[mathescape, language=OCaml]
  |> intros' ["Hlam"; "a"; "e_a"; "t1"; "t2"; ""] %> case "value"
(* Proof state:
[ e = lam (a.e_a) ; t = arrow t1 t2 ]
[
  Hlam : Typing e_a {cons a t1 nil} t2 $\wedge$ Type t1 ;
  $\cdots$
]
$\vdash$ Value e
*)
     %> case "lam"
     %> case "lam"
     %> exists' ["a"; "e_a"]
     %> solve
\end{lstlisting}
Then \tt{e} must be an application and thus must be reducing by taking steps,
so we apply inductive hypothesis on its sub-expressions \tt{e1} and \tt{e2}
and examine the possible cases.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
  |> intros' ["Happ"; "e1"; "e2"; "t2"; ""; ""] %> case "steps"
  |> add_assumption_parse "He1" "Progressive e1"
     %> apply_assm_spec "IH" ["e1"; "arrow t2 t"] %> solve
  |> add_assumption_parse "He2" "Progressive e2"
     %> apply_assm_spec "IH" ["e2"; "t2"] %> solve
  |> subst "e" "app e1 e2"
(* Proof state:
[ e = app e1 e2 ]
[
  Happ1 : Typing e1 nil {arrow t2 t} ;
  Happ2 : Typing e2 nil t2 ;
  He1 : Progressive e1 ;
  He2 : Progressive e2 ;
]
$\vdash$ $\exists$ e' : term. Steps {app e1 e2} e'
*)
\end{lstlisting}
First we consider the case of both \tt{e1} and \tt{e2} being a value.
From \tt{canonical\_form} theorem we know then \tt{e1} must be an abstraction
--- we just need to ensure the Prover that all preconditions are met.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
  |> destruct_assm "He1" %> intros ["Hv1"]
    %> destruct_assm "He2" %> intros ["Hv2"]  (* Value e1, Value e2 *)
    %> add_assumption_thm_spec "He1lam"
         canonical_form ["e1"; "arrow t2 t"]
(* Proof state:
[ e = app e1 e2 ]
[
  He1lam : (Value e1) $\implies$ (Typing e1 nil {arrow t2 t})
         $\implies$ $\exists$ a : atom. $\exists$ e'1 : term. [e1 = lam (a.e'1)] $\wedge$ Term e'1 ;
  Hv1 : Value e1 ;
  Hv2 : Value e2 ;
  ...
]
$\vdash$ $\exists$ e' : term. Steps {app e1 e2} e'
*)
    %> apply_in_assm "He1lam" "Hv1"
    %> apply_in_assm "He1lam" "Happ_1"
    %> destruct_assm' "He1lam" ["a"; "e_a"; ""]
    %> subst "e1" "lam (a.e_a)"
(* Proof state:
[ e = app e1 e2 ; e1 = lam (a.e_a) ]
[
  He1lam : Term e_a ;
  ...
]
$\vdash$ $\exists$ e' : term. Steps {app (lam (a.e_a)) e2} e'
*)
\end{lstlisting}
Then we need to find the \tt{e'} that \tt{app e1 e2} reduces to, and now
that we know \tt{e1} is an abstraction, then we can use beta-reduction rule
and find the term of abstracion body \tt{e\_a} with argument \tt{a}
substituted with \tt{e2}. Again, we ensure the Prover that preconditions are met
and destruct on the final assumption to extract the term that we searched for: \tt{e\_a'}.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
    %> add_assumption_thm_spec "He_a"
         subst_exists ["a"; "e2"; "e_a"]
(* Proof state:
[ ... ]
[
  He_a : (Value e2) $\implies$ (Term e_a) $\implies$ $\exists$ e' : term. Sub e_a a e2 e' ;
  ...
]
$\vdash$ $\exists$ e' : term. Steps e e'
*)
    %> apply_in_assm "He_a" "Hv2"
    %> apply_in_assm "He_a" "He1lam"
    %> destruct_assm' "He_a" ["e_a'"]
    %> exists "e_a'"
(* Proof state:
[ ... ]
[
  He_a : Sub e_a a e2 e_a' ;
  ...
]
$\vdash$ Steps {app (lam (a.e_a)) e2} e_a'
*)
    %> case "app" %> exists' ["a"; "e_a"; "e2"] %> solve
(* Proof state:
[ ... ]
[ ... ]
$\vdash$ Value e2 $\wedge$ Sub e_a a e2 e_a'
*)
    %> destruct_goal %> apply_assm "Hv2" %> apply_assm "He_a"
\end{lstlisting}
Now what's left is to examine straightforward cases where either \tt{e1} or \tt{e2} steps.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
  |> intros' ["Hs2"; "e2'"] (* Value e1, Steps e2 e2' *)
     %> exists "app e1 e2'"
(* Proof state:
[ ... ]
[
  Hv1 : Value e1 ;
  Hs2 : Steps e2 e2' ;
  ...
]
$\vdash$ Steps {app e1 e2} {app e1 e2'}
*)
    %> case "app_r"
    %> exists' ["e1"; "e2"; "e2'"]
    %> repeat solve
(* Proof state:
[ ... ]
[ ... ]
$\vdash$ Value e1 $\wedge$ Steps e2 e2'
*)
    %> destruct_goal
    %> apply_assm "Hv1"
    %> apply_assm "Hs2"
  |> intros' ["Hs1"; "e1'"] (* Steps e1 *)
(* Proof state:
[ ... ]
[
  Hs1 : Steps e1 e1' ;
  ...
]
$\vdash$ Steps {app e1 e2} {app e1' e2}
*)
    %> exists "app e1' e2"
    %> case "app_l"
    %> exists' ["e1"; "e1'"; "e2"]
    %> repeat solve
    %> apply_assm "Hs1"
  |> apply_assm "Happ_2" %> apply_assm "Happ_1"
  |> qed
\end{lstlisting}
Now, to prove \it{Preservation}, we will need some more lemmas:

1. Substitution lemma:
if term \tt{e} has a type \tt{t} in enviroment \tt{\{cons a ta env\}},
then we can substitute \tt{a} for any value \tt{v} of type \tt{ta} in \tt{e} without breaking the typing.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codepurple}]
let sub_lemma_thm = lambda_thm
  "$\forall$ e env t :term.
   $\forall$ a : atom. $\forall$ ta :term.
   $\forall$ v e' :term.
     (Typing v env ta) $\implies$
     (Typing e {cons a ta env} t) $\implies$
     (Sub e a v e') $\implies$
       (Typing e' env t)"
\end{lstlisting}

2. Weakening lemma: for any enviroment \tt{env1}, we can use larger enviroment \tt{env2} without breaking the typing.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codepurple}]
let weakening_lemma_thm = lambda_thm
  "$\forall$ e env1 t env2 : term.
     (Typing e env1 t) $\implies$
     (EnvInclusion env1 env2) $\implies$
       (Typing e env2 t)"
\end{lstlisting}

3. Lambda abstraction typing inversion:
If term \tt{lam (a.e)} has a type \tt{\{arrow t1 t2\}} in environment \tt{env},
then it must be that the body \tt{e} has a type \tt{t2} in enviroment extended with the argument \tt{\{cons a t1 env\}}.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codepurple}]
let lambda_typing_inversion_thm = lambda_thm
  "$\forall$ a :atom. $\forall$ e env t1 t2 :term.
     (Typing {lam (a.e)} env {arrow t1 t2}) $\implies$
       (Typing e {cons a t1 env} t2)"
\end{lstlisting}
To maintain reader engagement and prevent excessive technicality, we will omit
here the proofs of rather obvious lemmas 2 and 3 and instead focus on the more
important lemma 1:
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
let sub_lemma =
  proof' sub_lemma_thm
  |> by_induction "e0" "IH"
     %> repeat intro %> intros ["Hv"; "He"; "Hsub"]
(* Proof state:
[ ]
[
  He : Typing e {cons a ta env} t ;
  Hsub : Sub e a v e' ;
  Hv : Typing v env ta ;
  IH : $\forall$ e0 : term. [e0 $\cshlt$ e] $\implies$
        $\forall$ env'1 t'1 : term. $\forall$ a'1 : atom. $\forall$ ta'1 v'1 e''1 : term.
          Typing v'1 env'1 ta'1 $\implies$
          Typing e0 {cons a'1 ta'1 env'1} t'1 $\implies$
          Sub e0 a'1 v'1 e''1 $\implies$
            Typing e''1 env'1 t'1
]
$\vdash$ Typing e' env t
*)
%> destruct_assm "He"
\end{lstlisting}
First case is that \tt{e} is some variable \tt{b}, with first subcases
that it is equal to \tt{a} and substitutes to \tt{v}:
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
  |> intros' ["Hb"; "b"; ""]
     %> destruct_assm "Hsub"
     %> ( intros' ["Heq"; ""; ""]
(* Proof state:
[ e = a ; e' = v ; e = b ]
[
  Hb : InEnv {cons a ta env} b t ;
  Hv : Typing v env ta ;
  ...
]
$\vdash$ Typing e' env t
*)
\end{lstlisting}
Now because in the goal \tt{e'} has type \tt{t}, but in assumption \tt{Hv} it
has \tt{ta}, then we again case-analyse the assumption \tt{Hb}
and get that either \tt{t = ta} or arrive at contradiction:
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
        %> destruct_assm "Hb"
        %> ( intros' ["Heq"; "env'"; ""] (* t = ta *)
             %> apply_assm "Hv" )
        %> ( intros' ["Hdiff"; "b'"; "t'"; "env'"; ""; ""] (* a $\cneq$ b *)
             %> discriminate )
        \end{lstlisting}
Second subcase is that \tt{b} is be different than
\tt{a} and thus is not be affected by the subistution.
We will again case-analyse \tt{Hb} assumption to extract additional facts.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
     %> ( intros' ["Hdiff"; "b'"; ""; ""; ""] (* a $\cneq$ b *)
        %> destruct_assm "Hb"
        %> ( intros' ["Heq"; "env'"; ""] (* a = b *)
             %> discriminate )
        %> ( intros' ["Hdiff"; "a'"; "ta'"; "env'"; ""; ""]
(* Proof state:
[  e = b ; e' = b ; a $\cneq$ b ; ... ]
[
  Hdiff : InEnv env' b t ;
  ...
]
$\vdash$ Typing e' env t
*)
             %> case "var"
             %> exists "b"
             %> solve
             %> assumption )
\end{lstlisting}
Second case is that \tt{e} is some abstraction \tt{lam (b.e\_b)}.
Because of the way we defined subsitution, abstraction argument must
be different than the substituted variable and not occur in the substitutee value
--- which is made possible by swapping atoms while maintaining alpha-equality.
Consequence of that is when we destruct \tt{Hsub} we get that
\tt{e = lam (c.e\_c)} and \tt{e' = lam (c.e\_c')}
--- while \tt{b.e\_b} and \tt{c.e\_c} are equal, \tt{b} and \tt{c} don't have to be.
Abstracting the mundane details to auxiliary lemmas allows us to present the
derivation in a simple chain of applications and assumptions:
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
  |> intros' ["Hlam"; "b"; "e_b"; "t1"; "t2"; ""; ""; ""]
     %> destruct_assm "Hsub"
     %> intros' ["Hsub"; "c"; "e_c"; "e_c'"; ""; ""; ""; ""]
     %> case "lam"
     %> exists' ["c"; "e_c'"; "t1"; "t2"]
     %> repeat solve
(* Proof state:
[ e = lam (b.e_b) ; e = lam (c.e_c) ; e' = lam (c.e_c') ;
  a $\cneq$ c ; c # v ; t = arrow t1 t2 ]
[
  Hsub : Sub e_c a v e_c' ;
  Hlam_1 : Type t1 ;
  Hlam_2 : Typing e_b {cons b t1 (cons a ta env)} t2 ;
  Hv : Typing v env ta ;
  ...
]
$\vdash$ Type t1 $\wedge$ Typing e_c' {cons c t1 env} t2
*)
     %> destruct_goal
     %> assumption
     %> apply_assm_spec
        "IH" ["e_c"; "cons c t1 env"; "t2"; "a"; "ta"; "v"; "e_c'"]
     (* [e_c $\cshlt$ e] $\implies$ Typing v {cons c t1 env} ta $\implies$
          Typing e_c {cons a ta (cons c t1 env)} t2 $\implies$
            Sub e_c a v e_c' $\implies$ Typing e_c' {cons c t1 env} t2  *)
     %> solve
     %> ( apply_thm_spec
            cons_fresh_typing ["v"; "env"; "ta"; "c"; "t1"]
            (* [c # v] $\implies$ Typing v env ta $\implies$
                 Typing v {cons c t1 env} ta *)
          %> solve
          %> apply_assm "Hv" )
     %> ( apply_thm_spec
           typing_env_shuffle ["e_c"; "env"; "t2"; "c"; "t1"; "a"; "ta"]
           (* [c $\cneq$ a] $\implies$
                Typing e_c {cons c t1 (cons a ta env)} t2 $\implies$
                  Typing e_c {cons a ta (cons c t1 env)} t2 *)
          %> solve
          %> apply_thm_spec swap_lambda_typing
               ["b"; "e_b"; "c"; "e_c"; "cons a ta env"; "t1"; "t2"]
               (* [b.e_b = c.e_c] $\implies$
                    Typing e_b {cons b t1 (cons a ta env)} t2 $\implies$
                      Typing e_c {cons c t1 (cons a ta env)} t2 *)
          %> solve
          %> apply_assm "Hlam_2" )
     %> apply_assm "Hsub"
\end{lstlisting}
Finally, we consider the case that \tt{e} is an application \tt{e1 e2},
which goes straightly from inductive hypothesis, so we omit this part here.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
  |> intros' ["Happ"; "e1"; "e2"; "t2"; ""; ""]
     %> intros' ["Hsub"; "_e1"; "_e2"; "e1'"; "e2'"; ""; ""; ""]
     %> case "app"
     %> exists' ["e1'"; "e2'"; "t2"]
     %> solve
(* Proof state:
[ e = app e1 e2 ; e' = app e1' e2']
[
  Happ_1 : Typing e1 {cons a ta env} {arrow t2 t} ;
  Happ_2 : Typing e2 {cons a ta env} t2 ;
  Hsub_1 : Sub e1 a v e1' ;
  Hsub_2 : Sub e2 a v e2' ;
  ...
]
$\vdash$ Typing e1' env {arrow t2 t} $\wedge$ Typing e2' env t2
*)
     ...
  |> qed
\end{lstlisting}
Now that we've shown the \tt{sub\_lemma}, we can go on with the final proof
of \it{preservation}.
The proof goes through induction on term \tt{e} the case analysis on assumption \tt{Steps e e'}.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
let preservation = proof' preservation_thm
  |> by_induction "e0" "IH"
  |> intro %> intro %> intro %> intros ["Htyp"; "Hstep"]
(* Proof state:
[ ]
[
  Hstep : Steps e e' ;
  Htyp : Typing e env t ;
  IH : $\forall$ e0 : term. [e0 $\cshlt$ e]
         $\implies$ $\forall$ e'1 env'1 t'1 : term. (Typing e0 env'1 t'1)
           $\implies$ (Steps e0 e'1)
             $\implies$ Typing e'1 env'1 t'1
]
$\vdash$ Typing e' env t
*)
  |> destruct_assm "Hstep"
\end{lstlisting}
First two cases are rather simple: \tt{e} is \tt{app e1 e2} and either \tt{e1} or \tt{e2} take a step.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
  |> intros' ["He1"; "e1"; "e1'"; "e2"; ""; ""]
     %> case "app"
     %> exists' ["e1'"; "e2"; "t2"]
     %> solve
(* Proof state:
[ e = app e1 e2 ; e' = app e1' e2 ]
[
  Happ_2 : Typing e2 env t2 ;
  Happ_1 : Typing e1 env {arrow t2 t} ;
  He1 : Steps e1 e1 ;
  ...
]
$\vdash$ Typing e1' env {arrow t2 t} $\wedge$ Typing e2 env t2
*)
     %> destruct_goal
       %> (apply_assm_spec "IH" ["e1"; "e1'"; "env"; "arrow t2 t"]
            (* [e1 $\cshlt$ e] $\implies$
                 Typing e1 env {arrow t2 t} $\implies$
                   Steps e1 e1' $\implies$
                     Typing e1' env {arrow t2 t} *)
            %> solve
            %> apply_assm "Happ_1"
            %> apply_assm "He1" )
       %> apply_assm "Happ_2"
  |> intros' ["He2"; "v1"; "e2"; "e2'"; ""; ""; ""]
     %> case "app"
     %> exists' ["v1"; "e2'"; "t2"]
     %> solve
(* Proof state:
[ e = app e1 e2 ; e' = app e1' e2 ]
[
  He2 : Value v1 $\wedge$ Steps e2 e2' ;
  ...
]
$\vdash$ Typing e1 env {arrow t2 t} $\wedge$ Typing e2' env t2
*)
     %> destruct_goal
       %> apply_assm "Happ_1"
       %> ( apply_assm_spec "IH" ["e2"; "e2'"; "env"; "t2"]
            (* [e2 $\cshlt$ e] $\implies$
                 Typing e2 env t2 $\implies$
                   Steps e2 e2' $\implies$
                     Typing e2' env t2 *)
            %> solve
            %> apply_assm "Happ_2"
            %> apply_assm "He2_2" )
\end{lstlisting}
The next, final case is where we will need the established lemmas:
application \tt{app e1 e2} beta-reduces into some term \tt{e'} and we use the \tt{sub\_lemma} to show
that \tt{e'} still types.
\begin{lstlisting}[mathescape,language=OCaml,escapebegin=\color{codegreen}]
  |> intros' ["Hbeta"; "a"; "e_a"; "v"; ""; ""]
(* Proof state:
[ e = app (lam (a.e_a)) v ]
[
  Happ_2 : Typing v env t2 ;
  Happ_1 : Typing (lam (a.e_a)) env {arrow t2 t} ;
  Hbeta_1 : Value v ;
  Hbeta_2 : Sub e_a a v e' ;
  ...
]
$\vdash$ Typing e' env t
*)
    %> apply_thm_spec
         sub_lemma ["e_a"; "env"; "t"; "a"; "t2"; "v"; "e'"]
    (* Typing v env t2 $\implies$
         Typing e_a {cons a t2 env} t $\implies$
           Sub e_a a v e' $\implies$
             Typing e' env t *)
    %> apply_assm "Happ_2"
    %> ( apply_thm_spec
           lambda_typing_inversion ["a"; "e_a"; "env"; "t2"; "t"]
           (* Typing {lam (a.e_a)} env {arrow t2 t}
              $\implies$ Typing e_a {cons a t2 env} t *)
         %> apply_assm "Happ_1" )
    %> apply_assm "Hbeta_2"
  |> qed
\end{lstlisting}
And that's it.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion}

In summary, we've introduced and demonstrated a specialized variant of Nominal Logic,
designed for reasoning about variable binding
through the utilization of constraints solving.
We've also successfully implemented this logic in OCaml,
complemented by essential tools, including a proof assistant.

Through the proofs of classical properties of simply typed lambda calculus
we have validated the logic's suitablility for reasoning about programming languages.
However, the true potential of this framework is expected to shine when applied to
specific theorems reliant on the notions of variable binding.

We must also acknowledge that our framework is still in its infancy,
requiring substantial refinement to ensure a user-friendly experience, as the
awkardness and low-level nature of the current tooling obscures the benefits
of underlying constraint-based sublogic.
Consequently, it cannot be directly compared to other theorem-proving frameworks like Coq or Agda.

Nonetheless, we are confident that with enough refinement,
our framework can prove to be a valuable resource for the specific use cases and
remain enthusiastic about the framework's potential to
contribute to the field of formal methods and logic-based reasoning.

%%%%% BIBLIOGRAFIA

\printbibliography

\begin{appendices}
\chapter{Solver rules}
Goal-reducing equality rules:
$$\inference{
}{
  \cEnv ; \icEnv \vDash \atomv = \atomv
}
\qquad
\inference{
}{
  \cEnv ; \icEnv \vDash \termv = \termv
}
\qquad
\inference{
}{
  \cEnv ; \icEnv \vDash \symb = \symb
}
\qquad
\inference{
  \cEnv ; \icEnv \vDash \term_1 = \term_2
  &
  \cEnv ; \icEnv \vDash \term_1' = \term_2'
}{
  \cEnv ; \icEnv \vDash \term_1 \term_1' = \term_2 \term_2'
}
$$
$$
\inference{
  \cEnv ; \icEnv \vDash \atomexp_1 \cfresh \tbind{\atomexp_2}\term_2
  \\
  \cEnv ; \icEnv \vDash \term_1 = \permswap{\atomexp_1}{\atomexp_2} \term_2
}{
  \cEnv ; \icEnv \vDash \tbind{\atomexp_1} \term_1 = \tbind{\atomexp_2} \term_2
}
\qquad
\inference{
  \atomv \cneq \atomexp_1, \atomv \cneq \atomexp_2, \cEnv ; \icEnv \vDash \atomv     = \atomexp \\
  \atomv \ceq  \atomexp_1, \atomv \cneq \atomexp_2, \cEnv ; \icEnv \vDash \atomexp_2 = \atomexp \\
  \atomv \ceq  \atomexp_2, \cEnv ; \icEnv \vDash \atomexp_1 = \atomexp
}{
  \cEnv ; \icEnv \vDash \atomv = \permswap{\atomexp_1}{\atomexp_2}{\atomexp}
}
$$
$$
\inference{
  \cEnv ; \icEnv \vDash \atomv = \perm^{-1} \atomexp
}{
  \cEnv ; \icEnv \vDash \perm \atomv = \atomexp
}
\qquad
\inference{
  \cEnv ; \icEnv \vDash \termv_1 = \pi_1^{-1} \pi_2 \termv_2
}{
  \cEnv ; \icEnv \vDash \pi_1 \termv_1 = \pi_2 \termv_2
}
$$
$$
\inference{
  \cEnv ; \icEnv \vDash \pi \text{ idempotent on } \termv
}{
  \cEnv ; \icEnv \vDash \termv = \pi \termv
}
\qquad
\inference{
  \forall \atomv \in \pi.\;
    \cEnv ; \icEnv \vDash \atomv = \pi \atomv \;\vee\;
    \cEnv ; \icEnv \vDash \atomv \cfresh \termv
  }{
  \cEnv ; \icEnv \vDash \pi \text{ idempotent on } \termv
}
$$
Goal-reducing freshness rules:
$$\inference{
  \atomv_1 \cneq \atomv_2 \in \icEnv
}{
  \cEnv ; \icEnv \vDash \atomv_1 \cfresh \atomv_2
}
\qquad
\inference{
  \atomv \cfresh \termv \in \icEnv
}{
  \cEnv ; \icEnv \vDash \atomv \cfresh \termv
}
\qquad
\inference{
}{
  \cEnv ; \icEnv \vDash \atomv \cfresh \symb
}
$$
$$\inference{
  \atomv \cneq \atomexp, \cEnv ; \icEnv \vDash \atomv \cfresh \term
}{
  \cEnv ; \icEnv \vDash \atomv \cfresh \tbind{\atomexp}{\term}
}
\qquad
\inference{
  \cEnv ; \icEnv \vDash \atomv \cfresh \term_1 &
  \cEnv ; \icEnv \vDash \atomv \cfresh \term_2
}{
  \cEnv ; \icEnv \vDash \atomv \cfresh \term_1 \term_2
}
$$
$$
\inference{
  \atomv \cneq \atomexp_1, \atomv \cneq \atomexp_2, \cEnv ; \icEnv \vDash \atomv     \cfresh \atomexp \\
  \atomv \ceq  \atomexp_1, \atomv \cneq \atomexp_2, \cEnv ; \icEnv \vDash \atomexp_1 \cfresh \atomexp \\
                          \atomv \ceq  \atomexp_2 , \cEnv ; \icEnv \vDash \atomexp_2 \cfresh \atomexp
}{
  \cEnv ; \icEnv \vDash \atomv \cfresh \permswap{\atomexp_1}{\atomexp_2}{} \atomexp
}
\qquad
\inference{
  \atomv \cneq \atomexp_1, \atomv \cneq \atomexp_2, \cEnv ; \icEnv \vDash \atomv     \cfresh \pi \termv \\
  \atomv \ceq  \atomexp_1, \atomv \cneq \atomexp_2, \cEnv ; \icEnv \vDash \atomexp_1 \cfresh \pi \termv \\
                          \atomv \ceq  \atomexp_2 , \cEnv ; \icEnv \vDash \atomexp_2 \cfresh \pi \termv
}{
  \cEnv ; \icEnv \vDash \atomv \cfresh \permswap{\atomexp_1}{\atomexp_2}{\pi} \termv
}
$$
Goal reducing shape rules:
$$
\inference{
}{
  \cEnv ; \icEnv \vDash \shatom \csheq \shatom
}
\qquad
\inference{
}{
  \cEnv ; \icEnv \vDash \symb \csheq \symb
}
$$
$$
\inference{
  \termv_1 \csheq \termv_2 \in \icEnv
}{
  \cEnv ; \icEnv \vDash \termv_1 \csheq \termv_2
}
\qquad
\inference{
  \termv  \csheq \shape' \in \icEnv &
  \cEnv ; \icEnv \vDash \shape'  \csheq \shape
}{
  \cEnv ; \icEnv \vDash \termv  \csheq \shape
}
$$
$$\inference{
  \cEnv ; \icEnv \vDash \shape_1 \csheq \shape_2
}{
  \cEnv ; \icEnv \vDash \shbind \shape_1 \csheq \shbind \shape_2
}
\qquad
\inference{
  \cEnv ; \icEnv \vDash \shape_1 \csheq \shape_2
  &
  \cEnv ; \icEnv \vDash \shape_1' \csheq \shape_2'
}{
  \cEnv ; \icEnv \vDash \shape_1 \shape_1' \csheq \shape_2 \shape_2'
}
$$
Goal-reducing subshape rules:
$$\inference{
  \cEnv ; \icEnv \vDash \shape_1 \csheq \shape_2
}{
  \cEnv ; \icEnv \vDash \shape_1 \cshlt \shbind \shape_2
}
\qquad
\inference{
  \cEnv ; \icEnv \vDash \shape_1 \cshlt \shape_2
}{
  \cEnv ; \icEnv \vDash \shape_1 \cshlt \shbind \shape_2
}
$$
$$\inference{
  \cEnv ; \icEnv \vDash \shape_1 \csheq \shape_2
}{
  \cEnv ; \icEnv \vDash \shape_1 \cshlt \shape_2 \shape_2'
}
\qquad
\inference{
  \cEnv ; \icEnv \vDash \shape_1 \csheq \shape_2'
}{
  \cEnv ; \icEnv \vDash \shape_1 \cshlt \shape_2 \shape_2'
}
\qquad
\inference{
  \cEnv ; \icEnv \vDash \shape_1 \cshlt \shape_2
}{
  \cEnv ; \icEnv \vDash \shape_1 \cshlt \shape_2 \shape_2'
}
\qquad
\inference{
  \cEnv ; \icEnv \vDash \shape_1 \cshlt \shape_2'
}{
  \cEnv ; \icEnv \vDash \shape_1 \cshlt \shape_2 \shape_2'
}
$$
$$\inference{
  \shape_2 \cshlt \termv \in \icEnv
  &
  \cEnv ; \icEnv \vDash \shape_2 \csheq \termv
}{
  \cEnv ; \icEnv \vDash \shape_1 \cshlt \termv
}
\qquad
\inference{
  \shape_2 \cshlt \termv \in \icEnv
  &
  \cEnv ; \icEnv \vDash \shape_2 \cshlt \termv
}{
  \cEnv ; \icEnv \vDash \shape_1 \cshlt \termv
}
$$
Assumption-reducing equality rules:
$$
\inference{
   \termv = \pi^{-1} \term, \cEnv ; \icEnv \vDash \sconstr
}{
   \pi \termv = \term, \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
  \pi \text{ idempotent on } \termv, \cEnv ; \icEnv \vDash \sconstr
}{
   \termv = \pi \termv, \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\inference{
  \vDash \text{ idempotent on } \termv \\
  \cEnv ; \icEnv \vDash \sconstr
}{
   \pi \text{ idempotent on } \termv, \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
  (\forall \atomv \in \pi.\;
    \cEnv ; \icEnv \vDash \atomv = \pi \atomv \;\vee\;
    \cEnv ; \icEnv \vDash \atomv \cfresh \termv), \cEnv ; \icEnv \vDash \sconstr
}{
\pi \text{ idempotent on } \termv, \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
   \cEnv\subst{\termv}{\term} ; \icEnv\subst{\termv}{\term} \vDash \sconstr\subst{\termv}{\term}
}{
   \termv = \term, \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
   \cEnv \subst{\atomv_1}{\atomv_2}; \icEnv\subst{\atomv_1}{\atomv_2} \vDash \sconstr\subst{\atomv_1}{\atomv_2}
}{
  \atomv_1 \ceq \atomv_2, \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
  \atomv \ceq \pi^{-1} \atomexp, \cEnv ; \icEnv \vDash \sconstr
}{
  \pi \atomv \ceq \atomexp, \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\inference{
  \atomv \cneq \atomexp_1, \atomv \cneq \atomexp_2, \atomv     \ceq \atomexp, \cEnv ; \icEnv \vDash \sconstr \\
  \atomv \ceq  \atomexp_1, \atomv \cneq \atomexp_2, \atomexp_2 \ceq \atomexp, \cEnv ; \icEnv \vDash \sconstr \\
                           \atomv \ceq  \atomexp_2, \atomexp_1 \ceq \atomexp, \cEnv ; \icEnv \vDash \sconstr
}{
  \atomv \ceq \permswap{\atomexp_1}{\atomexp_1} \atomexp, \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
}{
   \atomv \ceq \term_1 \term_2, \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\inference{
}{
   \atomv \ceq \tbind{\atomexp} \term , \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\inference{
}{
   \atomv \ceq \symb , \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
   \atomexp_1 \cfresh \tbind{\atomexp_2} \term_2,\; \term_1 = \permswap{\atomexp_1}{\atomexp_2}\term_2 , \; \cEnv ; \icEnv \vDash \sconstr
}{
   \tbind{\atomexp_1} \term_1 \ceq \tbind{\atomexp_2} \term_2 , \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\text{Other term constructors trivial}
$$
$$
\inference{
  \term_1 \ceq \term_2 , \; \term_1' \ceq \term_2', \;\cEnv ; \icEnv \vDash \sconstr
}{
   \term_1 \term_1' \ceq \term_2 \term_2' , \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\text{Other term constructors trivial}
$$
$$
\inference{
  \symb_1 \cneq \symb_2
}{
  \symb_1 \ceq \symb_2 , \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\inference{
  \cEnv ; \icEnv \vDash \sconstr
}{
  \symb\ceq \symb , \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\text{Other term constructors trivial}
$$
Assumption-reducing freshness rules:
$$
\inference{
  \cEnv ; \{\atomv_1 \cneq \atomv_2\} \cup \icEnv \vDash \sconstr
}{
  \atomv_1 \cneq \atomv_2, \; \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\inference{
  \cEnv ; \{\atomv \cfresh \termv\} \cup \icEnv \vDash \sconstr
}{
  \atomv \cfresh \termv, \; \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
  \atomv \cneq \atomexp_1, \atomv \cneq \atomexp_2, \atomv     \cfresh \atomexp, \cEnv ; \icEnv \vDash \sconstr \\
  \atomv \ceq  \atomexp_1, \atomv \cneq \atomexp_2, \atomexp_2 \cfresh \atomexp, \cEnv ; \icEnv \vDash \sconstr \\
                           \atomv \ceq  \atomexp_2, \atomexp_1 \cfresh \atomexp, \cEnv ; \icEnv \vDash \sconstr
}{
  \atomv \cfresh \permswap{\atomexp_1}{\atomexp_1} \atomexp, \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
  \atomv \cneq \atomexp_1, \atomv \cneq \atomexp_2, \atomv     \cfresh \perm\termv, \cEnv ; \icEnv \vDash \sconstr \\
  \atomv \ceq  \atomexp_1, \atomv \cneq \atomexp_2, \atomexp_2 \cfresh \perm\termv, \cEnv ; \icEnv \vDash \sconstr \\
                           \atomv \ceq  \atomexp_2, \atomexp_1 \cfresh \perm\termv, \cEnv ; \icEnv \vDash \sconstr
}{
  \atomv \cfresh \permswap{\atomexp_1}{\atomexp_1} \perm\termv, \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
  \atomv \cfresh \atomexp, \; \cEnv ; \icEnv \vDash \sconstr \\
  \atomv \cfresh \atomexp, \; \atomv \cfresh \term,\;\cEnv ; \icEnv \vDash \sconstr
}{
  \atomv \cfresh \tbind{\atomexp} \term , \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
  \atomv \cfresh \term_1 , \cEnv ; \icEnv \vDash \sconstr &
  \atomv \cfresh \term_2 , \cEnv ; \icEnv \vDash \sconstr
}{
  \atomv \cfresh \term_1 \term_2 , \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\inference{
  \cEnv ; \icEnv \vDash \sconstr
}{
  \atomv \cfresh \symb, \cEnv ; \icEnv \vDash \sconstr
}
$$
Assumption-reducing shape rules:
$$
\inference{
  \cEnv ; \{\termv_1 \csheq \termv_2\} \cup \icEnv \vDash \sconstr
}{
  \termv_1 \csheq \termv_2, \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\inference{
  \cEnv ; \{\termv \csheq \shape\} \cup \icEnv \vDash \sconstr
}{
  \termv \csheq \shape,\; \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
  \cEnv ; \icEnv \vDash \sconstr
}{
  \atomv_1 \csheq \atomv_2, \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\text{Other term constructors trivial}
$$
$$
\inference{
  \term_1 \csheq \term_2, \cEnv ; \icEnv \vDash \sconstr
}{
  \shbind\term_1 \csheq \shbind\term_2, \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\text{Other term constructors trivial}
$$
$$
\inference{
  \term_1  \csheq \term_2 , \cEnv ; \icEnv \vDash \sconstr
  &
  \term_1' \csheq \term_2', \cEnv ; \icEnv \vDash \sconstr
}{
  \term_1 \term_1' \csheq \term_2\term_2', \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\text{Other term constructors trivial}
$$
$$
\inference{
  \symb_1 \neq \symb_2
}{
  \symb_1 \csheq \symb_2 , \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\inference{
}{
  \symb \csheq \symb , \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\text{Other term constructors trivial}
$$
Assumption-reducing subshape ruleS:
$$
\inference{
  \cEnv ; \{\term \cshlt \termv\} \cup \icEnv \vDash \sconstr
}{
  \term \cshlt \termv, \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
  \term_1 \csheq \term_2, \cEnv ; \icEnv \vDash \sconstr
  &
  \term_1 \cshlt \term_2, \cEnv ; \icEnv \vDash \sconstr
}{
  \term_1 \cshlt \shbind \term_2, \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
  \term_1 \csheq \term_2, \cEnv ; \icEnv \vDash \sconstr
  &
  \term_1 \csheq \term_2', \cEnv ; \icEnv \vDash \sconstr
  \\
  \term_1 \cshlt \term_2, \cEnv ; \icEnv \vDash \sconstr
  &
  \term_1 \cshlt \term_2', \cEnv ; \icEnv \vDash \sconstr
}{
  \term_1 \cshlt \term_2 \term_2', \cEnv ; \icEnv \vDash \sconstr
}
$$
$$
\inference{
}{
  \term \cshlt \atomexp, \cEnv ; \icEnv \vDash \sconstr
}
\qquad
\inference{
}{
  \term \cshlt \symb, \cEnv ; \icEnv \vDash \sconstr
}
$$

\end{appendices}
\end{document}
